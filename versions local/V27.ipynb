{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "_kg_hide-input": false,
        "_kg_hide-output": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nprint(\"the code is running\")\n# from Package.Models import *\nimport torch\nimport pickle\nfrom torch import nn\nfrom torch.nn.modules.padding import ConstantPad1d,ReflectionPad1d\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\nfrom sklearn.model_selection import train_test_split\nfrom numba import jit\nfrom matplotlib import pyplot as plt\nfrom torch.autograd import Variable\nfrom sklearn.utils import shuffle\nfrom time import time\nfrom textblob import TextBlob as tb\nprint(\"import statements finished\")\n\ndef load_glove_model(gloveFile):\n    import numpy as np\n    print (\"Loading Glove Model\")\n    f = open(gloveFile,'r',encoding=\"utf8\")\n    print(\"file read\")\n    model = {}\n    count = 0\n    for line in f:\n        splitLine = line.split()\n        word = splitLine[0]\n        try:\n            embedding = np.array([float(val) for val in splitLine[1:]])\n            model[word] = embedding\n        except:\n            count = count+1\n            pass\n    print(count)\n    print (\"Done.\",len(model),\" words loaded!\")\n    \n    return model\n    \n    \n\n\n\n# from Package.Features import *\n# from Package import Newfile as nf\n# global X,Y\n\n## loading the glove vectors\nembedding_loc = \"../input/embeddings/glove.840B.300d/glove.840B.300d.txt\"\n# embedding_loc = \"../input/quora-insincere-questions-classification/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec\"\ntry:\n    glv\nexcept:\n    glv = load_glove_model(embedding_loc)\nprint(\"trying to load vectors\")    \nprint(len(glv))\n",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "the code is running\nimport statements finished\nLoading Glove Model\nfile read\n20\nDone. 2195884  words loaded!\ntrying to load vectors\n2195884\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "17f678f73ad2e3749853811c82499295a988f90f"
      },
      "cell_type": "code",
      "source": "DEBUG = True\nfrom nltk.tokenize import TweetTokenizer\nimport re\ntknzr = TweetTokenizer()\n\ntorch.manual_seed(2)\ndef preprocess(t):\n    \n    t = t.encode(\"ASCII\",\"ignore\").decode(\"utf-8\")\n    t = \" \".join(tknzr.tokenize(t))\n    t = str(t).lower()\n    t = re.sub(r'[\"\\'|?\"]','',t)\n    t = re.sub(r'[\\-]',' ',t)\n#     print(t)\n#     print(\"^^^^^^^^^^^^^^^^^^\")\n    return t\n\ndef log(*argv):\n    if DEBUG == True:\n        try:\n            print(argv)\n        except:\n            print(\"Error in printing\")\n\ndef get_batches(x,y,chunks = 400):\n    l = len(x)\n    cnt = int(np.round(int(l)/int(chunks)))\n    # log(cnt)\n    remain = l%chunks\n    rmt = remain/cnt\n    # log(rmt)\n    x_list = [x[each*cnt:(each*cnt)+cnt] for each in range(chunks+int(rmt)+2)]\n    y_list = [y[each*cnt:(each*cnt)+cnt] for each in range(chunks+int(rmt)+2)]\n    return x_list,y_list\n\n\n@jit\ndef numba_mean(loss_list):\n    return np.array(loss_list).mean()\n    \n\n",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "95bafeac2b71cd745c648e79dd72494b490433b6",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)\ndtype = torch.FloatTensor\n# CUDA_LAUNCH_BLOCKING=1\ntorch.set_default_tensor_type('torch.FloatTensor')\n\n## Model definition\nclass encoder_rnn(nn.Module):\n    def __init__(self,input_dim, hidden_dim, layer_dim, output_dim):\n        super(encoder_rnn,self).__init__()\n        self.rnn = nn.GRU(input_dim, hidden_dim, layer_dim, batch_first=True,bidirectional = True)\n        self.layer_dim = layer_dim\n        self.hidden_dim = hidden_dim\n        self.fc = net = nn.Sequential(\n                  nn.Linear(hidden_dim*2, hidden_dim*4),\n#                   nn.BatchNorm1d(num_features = (hidden_dim*4)),\n                  nn.ReLU(),\n                  nn.Linear(hidden_dim*4,output_dim),\n                  nn.Sigmoid()\n                  )\n        self.relu = nn.ReLU()\n        self.bn1 = nn.BatchNorm1d(num_features = hidden_dim*4)\n\n    def forward(self,x):\n        for e in range(len(x)):\n            X = (torch.from_numpy(x[e])[None,None,:]).type(dtype)            \n            if e == 0:\n#                 h0 = (torch.randn(self.layer_dim*2, 1, self.hidden_dim).type(dtype),torch.randn(self.layer_dim*2, 1, self.hidden_dim).type(dtype))\n                h0 = torch.randn(self.layer_dim*2, 1, self.hidden_dim).type(dtype)\n                output,hidden = self.rnn(X,h0)\n            else:\n                output,hidden = self.rnn(X,hidden)\n        output = (output).view(-1)\n        output = self.relu(output)\n        final = self.fc(output)\n        return final\ndef init_weights(m):\n    if type(m) == nn.Linear:\n        print(\"Xavier applied\")\n        torch.nn.init.xavier_uniform(m.weight)\n        m.bias.data.fill_(0.01)\n    \n## initiate a model   \nmodel  = encoder_rnn(301,100,2,1)\n# torch.nn.init.xavier_uniform(model.weight)\nmodel.apply(init_weights)\n# model = model.cuda()\n\n## loading the training data\n# q = pd.read_csv(\"../input/quora-insincere-questions-classification/train.csv\",index_col = None,encoding = \"iso-8859-1\")\nq = pd.read_csv(\"../input/train.csv\",index_col = None,encoding = \"iso-8859-1\")\nsin = q[q[\"target\"] == 0]\ninsin = q[q[\"target\"] == 1]\nsin = sin.sample(frac = 0.10,random_state = 42)\nq = pd.concat([sin,insin])\nq = shuffle(q).reset_index(drop = True)\n# q = q[:100000]\nlog(\"Total rows \",q.shape)\n\ndef get_vectors(text,glv,pad = 250,get_pos = False):\n    import nltk\n    import numpy as np\n    glv_text = \" \".join([ each for each in text.split(\" \") if each in glv]) \n#     tp = [each for each in glv_text.split(\" \")]\n#     log(tp)\n    all_vectors = [glv[each] for each in glv_text.split(\" \")]\n    all_vectors = [np.append(all_vectors[i],(tb(each).sentiment[0])) for i,each in enumerate(glv_text.split(\" \"))]\n    temp = np.zeros((301))\n    \n    if pad != None:\n        all_vectors = all_vectors[:pad]\n        if len(all_vectors) <pad:\n            temp_range = pad-len(all_vectors)\n            temp_list = temp.tolist()\n            [all_vectors.append(temp_list)for each in range(temp_range)]\n    if len(all_vectors)== 0:\n        log(\"The words in this text has no vectors\")\n        log(text)\n        all_vectors.append(temp)\n    all_vectors = np.array(all_vectors)\n    if get_pos == True:\n        pos_vector = get_pos_tag(text,glv)\n        if len(all_vectors)!= len(pos_vector):\n            print(\"Pos Error detected\")\n        all_vectors = [np.concatenate((each,pos_vector[1])) for i,each in enumerate(all_vectors) if len(all_vectors)== len(pos_vector)]\n    return all_vectors\n\n\n\nlog(q.groupby(\"target\")[\"qid\"].count())\nlog(\"Considered rows \",q.shape)\nq[\"question_text\"] = [ preprocess(each) for each in  q[\"question_text\"]]\n# q.preprocess(remove_stopwords = False,lemmatize = False)\nlog(\"preprocessing words complete\")\nq[\"x\"]  = q[\"question_text\"]\nq[\"y\"] = q[\"target\"]\n\n## test train split\nx,xt,y,yt = train_test_split(q['x'],q['y'],test_size=0.005, random_state=42)\nx = x.reset_index(drop = True)\nxt = xt.reset_index(drop = True)\ny = y.reset_index(drop = True)\nyt =yt.reset_index(drop = True)\n\n## readying the vectors for the test data\nxt = [get_vectors(each,glv,pad= None) for each in xt]\n\nlog(\"Vectorization complete\")\n\n## obtaining batches\nbatches = 250\nx_batches,y_batches = get_batches(x,y,chunks = batches)\nx_batches = [each.reset_index(drop = True) for each in x_batches if len(each)!=0]\ny_batches = [each.reset_index(drop = True) for each in y_batches if len(each)!=0]\n\nlog(\"splitting the batches is complete\")  \nlog(\"The shape of each batch is \",x_batches[0].shape)      \nlog(\"The shape of test data is \",len(xt))      \n\ndef feed(x,y,backprop = False,epoch=1):\n    t1 = time()\n    loss_list = []\n    for i,each in enumerate(x):\n        X = each\n        Y = (torch.from_numpy(np.array(y[i]))).type(dtype)\n        pred = model.forward(X)\n        loss =cross(pred,Y).type(dtype)\n        if backprop == True:\n            loss.backward()\n            optimizer.step()\n        loss_list.append(loss.item())\n    print(\"T:\",str(time()-t1))\n    return loss_list\n\nepoch = 1\nlr = 0.00001\ncheckpoint = 3\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\noptimizer.zero_grad()\ncross = nn.BCELoss()\n\nlog(\"Model training starts\")\n\nfor each in range(epoch):\n    for j,e in enumerate(x_batches):\n        x, y = x_batches[j],y_batches[j]\n        x = [get_vectors(each,glv,pad=None) for each in x]\n        train_cost = numba_mean(feed(x,y,backprop = True,epoch = each))  \n        \n        \n        log(\"Epoch num - \",each,\" and batch num \",j)\n        log(train_cost)\n        if j%7 == 0:\n            test_cost = numba_mean(feed(xt,yt,backprop = False,epoch = each))\n            log(test_cost)        \n        log(\"================================================\")\n        if j == 40:\n            break\n    break\nprint(\"completed\")\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "35d58a539b058d3534840f726e914052dc434d5e"
      },
      "cell_type": "code",
      "source": "# test = pd.read_csv(\"../input/quora-insincere-questions-classification/test.csv\",index_col = None)\ntest = pd.read_csv(\"../input/test.csv\",index_col = None)\ntest[\"question_text\"] = [preprocess(each) for each in test[\"question_text\"]]\nlog(\"preprocessing words complete\")\n\ntest[\"x\"]  = test[\"question_text\"]\n\n\nresult = []\nfor i,each in enumerate(test[\"x\"]):\n    # print(each)\n    xv = get_vectors(each,glv,pad = None)\n    pred =  model.forward(xv)\n    result.append(pred.item())\n    if i%5000 == 0:\n        log(i)\n        \n#%%\n    \ntest[\"result\"] = result\nthreshold = 0.4\ntest[\"prediction\"] = [ 1 if each > threshold else 0 for each in test.result]\ntest[[\"qid\",\"prediction\"]].to_csv(\"submission.csv\",index = None)\nprint(\"submitted\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b0037fd5a035cece310a1a44c83aae1ce90f1953"
      },
      "cell_type": "code",
      "source": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)\n",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}