{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "_kg_hide-input": false,
        "_kg_hide-output": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nprint(\"the code is running\")\n# from Package.Models import *\nimport torch\nimport pickle\nfrom torch import nn\nfrom torch.nn.modules.padding import ConstantPad1d,ReflectionPad1d\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\nfrom sklearn.model_selection import train_test_split\nfrom numba import jit\nfrom matplotlib import pyplot as plt\nfrom torch.autograd import Variable\nfrom sklearn.utils import shuffle\nfrom time import time\nfrom textblob import TextBlob as tb\nfrom nltk.tokenize import TweetTokenizer\nimport re\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_fscore_support\ntknzr = TweetTokenizer()\nprint(\"import statements finished\")\n\nDEBUG  = True\ntorch.manual_seed(2)\n\ndef log(*argv):\n    if DEBUG == True:\n        try:\n            print(argv)\n        except:\n            print(\"Error in printing\")\n            \ndef preprocess(t):    \n    t = t.encode(\"ASCII\",\"ignore\").decode(\"utf-8\")\n    t = \" \".join(tknzr.tokenize(t))\n    t = str(t).lower()\n    t = re.sub(r'[\"\\'|?\"]','',t)\n    t = re.sub(r'[\\-]',' ',t)\n    return t\n\ndef get_batches(x,y = 0,chunks = 400):\n    l = len(x)\n    cnt = int(np.round(int(l)/int(chunks)))\n    remain = l%chunks\n    rmt = remain/cnt\n    x_list = [x[each*cnt:(each*cnt)+cnt] for each in range(chunks+int(rmt)+2)]\n    try:\n        if y == 0:\n            return  x_list\n\n    except:\n        y_list = [y[each*cnt:(each*cnt)+cnt] for each in range(chunks+int(rmt)+2)]\n        return x_list,y_list        \n\n@jit\ndef numba_mean(loss_list):\n    return np.array(loss_list).mean()\n\ndef load_glove_model(gloveFile):\n    import numpy as np\n    print (\"Loading Glove Model\")\n    f = open(gloveFile,'r',encoding=\"utf8\")\n    print(\"file read\")\n    model = {}\n    count = 0\n    for line in f:\n        splitLine = line.split()\n        word = splitLine[0]\n        try:\n            embedding = np.array([float(val) for val in splitLine[1:]])\n            model[word] = embedding\n        except:\n            count = count+1\n            pass\n    print(count)\n    print (\"Done.\",len(model),\" words loaded!\")\n    return model\n\n## loading the glove vectors\n# embedding_loc = \"../input/embeddings/glove.840B.300d/glove.840B.300d.txt\"\nembedding_loc = \"../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec\"\ntry:\n    glv\nexcept:\n    glv = load_glove_model(embedding_loc)\nglv[\"\"] = np.zeros((300))\nprint(\"trying to load vectors\")    \nprint(len(glv))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "95bafeac2b71cd745c648e79dd72494b490433b6",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)\ndtype = torch.FloatTensor\ntorch.set_default_tensor_type('torch.FloatTensor')\n\nepoch = 1\nlr = 0.0006\ncheckpoint = 1000\ntest_checkpoint = 10\nthreshold = 0.5\nbatches = 300\n\n## Model definition\nclass encoder_rnn(nn.Module):\n    def __init__(self,input_dim, hidden_dim, layer_dim, output_dim):\n        super(encoder_rnn,self).__init__()\n        self.rnn = nn.GRU(input_dim, hidden_dim, layer_dim, batch_first=True,bidirectional = True)\n        self.layer_dim = layer_dim\n        self.hidden_dim = hidden_dim\n        self.fc  = nn.Sequential(\n                  nn.Linear(hidden_dim*2, hidden_dim*6),\n                   nn.BatchNorm1d(num_features = (hidden_dim*6)),\n                  nn.ReLU(),\n#                 nn.Linear(hidden_dim*6, hidden_dim*4),\n#                    nn.BatchNorm1d(num_features = (hidden_dim*4)),\n#                   nn.ReLU(),\n                  nn.Linear(hidden_dim*6,output_dim),\n                  nn.Sigmoid()\n                  )\n        self.relu = nn.ReLU()\n        self.bn1 = nn.BatchNorm1d(num_features = hidden_dim*2)\n\n    def forward(self,x):\n        batch_output = torch.zeros(1,self.hidden_dim*2)\n        for each in range(len(x)):\n            row = x[each]\n            for e in range(len(row)):\n                X =  (torch.from_numpy(row[e])[None,None,:]).type(dtype)   \n                if e == 0:\n    #                 h0 = (torch.randn(self.layer_dim*2, 1, self.hidden_dim).type(dtype),torch.randn(self.layer_dim*2, 1, self.hidden_dim).type(dtype))\n                    h0 = torch.randn(self.layer_dim*2, 1, self.hidden_dim).type(dtype)\n                    output,hidden = self.rnn(X,h0)\n                else:\n                    output,hidden = self.rnn(X,hidden)\n            output = (output).view(-1)\n            output = output[None,:]\n            batch_output = torch.cat((batch_output,output),0)\n\n        batch_output = (self.bn1(batch_output[1:]))\n        final = self.fc(batch_output) \n        return final\n    \ndef init_weights(m):\n    if type(m) == nn.Linear:\n        print(\"Xavier applied\")\n        torch.nn.init.xavier_uniform(m.weight)\n        m.bias.data.fill_(0.01)\n    \n## initiate a model   \nmodel  = encoder_rnn(301,20,1,1)\nmodel.apply(init_weights)\n\n## loading the training data\n# q = pd.read_csv(\"../input/quora-insincere-questions-classification/train.csv\",index_col = None,encoding = \"iso-8859-1\")\nq = pd.read_csv(\"../input/train.csv\",index_col = None,encoding = \"iso-8859-1\")\n# q = q[:50000]\nprint(\"Considered ....\",  str(q.shape))\nsin = q[q[\"target\"] == 0]\ninsin = q[q[\"target\"] == 1]\nsin = sin.sample(frac = 0.10,random_state = 42)\nq = pd.concat([sin,insin])\nq = shuffle(q).reset_index(drop = True)\nlog(\"Total rows \",q.shape)\n\ndef get_vectors(text,glv,pad = 250,get_pos = False):\n    import nltk\n    import numpy as np\n    glv_text = \" \".join([ each for each in text.split(\" \") if each in glv]) \n    all_vectors = [glv[each] for each in glv_text.split(\" \")]\n    all_vectors = [np.append(all_vectors[i],(tb(each).sentiment[0])) for i,each in enumerate(glv_text.split(\" \"))]\n    temp = np.zeros((301))\n    if pad != None:\n        all_vectors = all_vectors[:pad]\n        if len(all_vectors) <pad:\n            temp_range = pad-len(all_vectors)\n            temp_list = temp.tolist()\n            [all_vectors.append(temp_list)for each in range(temp_range)]\n    if len(all_vectors)== 0:\n        log(\"The words in this text has no vectors\")\n        log(text)\n        all_vectors.append(temp)\n    all_vectors = np.array(all_vectors)\n    if get_pos == True:\n        pos_vector = get_pos_tag(text,glv)\n        if len(all_vectors)!= len(pos_vector):\n            print(\"Pos Error detected\")\n        all_vectors = [np.concatenate((each,pos_vector[1])) for i,each in enumerate(all_vectors) if len(all_vectors)== len(pos_vector)]\n    return all_vectors\n\nlog(q.groupby(\"target\")[\"qid\"].count())\nlog(\"Considered rows \",q.shape)\nq[\"question_text\"] = [ preprocess(each) for each in  q[\"question_text\"]]\nlog(\"preprocessing words complete\")\nq[\"x\"]  = q[\"question_text\"]\nq[\"y\"] = q[\"target\"]\n\n## test train split\nx,xt,y,yt = train_test_split(q['x'],q['y'],test_size=0.005, random_state=42)\nx = x.reset_index(drop = True)\nxt = xt.reset_index(drop = True)\ny = y.reset_index(drop = True)\nyt =yt.reset_index(drop = True)\n\n## readying the vectors for the test data\nxt = [get_vectors(each,glv,pad= None) for each in xt]\n\nlog(\"Vectorization complete\")\n\n## obtaining batches\nx_batches,y_batches = get_batches(x,y,chunks = batches)\nx_batches = [each.reset_index(drop = True) for each in x_batches if len(each)!=0]\ny_batches = [each.reset_index(drop = True) for each in y_batches if len(each)!=0]\n\nlog(\"splitting the batches is complete\")  \nlog(\"The shape of each batch is \",x_batches[0].shape)      \nlog(\"The shape of test data is \",len(xt))      \n\ndef feed(x,y,backprop = False,epoch=1,threshold = 0.5):\n    t1 = time()\n    loss_list = []\n    X = x\n    Y = (torch.from_numpy(np.array(y))).type(dtype)\n    pred = model.forward(X)\n    loss =cross(pred,Y).type(dtype)\n    if backprop == True:\n        loss.backward()\n        optimizer.step()\n    loss_list.append(loss.item())\n    y_pred = pred.detach().numpy()\n    y_pred[y_pred >= threshold] = 1\n    y_pred[y_pred < threshold] = 0\n    y_pred = y_pred.flatten().tolist()\n    y_true = y.tolist()\n#     print(precision_recall_fscore_support(y_true = y_true,y_pred = y_pred ,average = \"micro\" ))\n    print(classification_report(y_true = y_true,y_pred = y_pred  ))\n    log(\"T:\",str(time()-t1))\n    return loss_list\n\n\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\noptimizer.zero_grad()\ncross = nn.BCELoss()\n\nlog(\"Model training starts\")\n\nfor each in range(epoch):\n    epoch_cost = []\n    for j,e in enumerate(x_batches):\n        x, y = x_batches[j],y_batches[j]\n        x = [get_vectors(each,glv,pad=None) for each in x]\n        train_cost = numba_mean(feed(x,y,backprop = True,epoch = each,threshold = threshold))  \n        epoch_cost.append(train_cost)\n        \n        log(\"Epoch num - \",each,\" and batch num \",j)\n        log(train_cost)\n        if j%test_checkpoint == 0:\n            log(\"TEST COST\")\n            test_cost = numba_mean(feed(xt,yt,backprop = False,epoch = each,threshold = threshold))\n            log(test_cost)        \n        log(\"================================================\")\n        if j == checkpoint:\n            break\n    log(\"EPOCH \",str(np.mean(epoch_cost)))\n#     break\nprint(\"completed\")\n",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Using device: cpu\nXavier applied\nXavier applied\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:56: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Considered .... (1306122, 3)\n('Total rows ', (203341, 3))\n(target\n0    122531\n1     80810\nName: qid, dtype: int64,)\n('Considered rows ', (203341, 3))\n('preprocessing words complete',)\n('Vectorization complete',)\n('splitting the batches is complete',)\n('The shape of each batch is ', (674,))\n('The shape of test data is ', 1017)\n('Model training starts',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([674])) that is different to the input size (torch.Size([674, 1])) is deprecated. Please ensure they have the same size.\n  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.62      0.69      0.66       413\n           1       0.41      0.34      0.38       261\n\n   micro avg       0.56      0.56      0.56       674\n   macro avg       0.52      0.52      0.52       674\nweighted avg       0.54      0.56      0.55       674\n\n('T:', '6.761310577392578')\n('Epoch num - ', 0, ' and batch num ', 0)\n(0.7044059038162231,)\n('TEST COST',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([1017])) that is different to the input size (torch.Size([1017, 1])) is deprecated. Please ensure they have the same size.\n  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.62      0.72      0.67       625\n           1       0.39      0.29      0.33       392\n\n   micro avg       0.55      0.55      0.55      1017\n   macro avg       0.51      0.51      0.50      1017\nweighted avg       0.53      0.55      0.54      1017\n\n('T:', '4.110818862915039')\n(0.6914972066879272,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.58      0.70      0.63       391\n           1       0.41      0.29      0.34       283\n\n   micro avg       0.53      0.53      0.53       674\n   macro avg       0.50      0.50      0.49       674\nweighted avg       0.51      0.53      0.51       674\n\n('T:', '6.926717758178711')\n('Epoch num - ', 0, ' and batch num ', 1)\n(0.7069763541221619,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.60      0.74      0.67       411\n           1       0.37      0.24      0.29       263\n\n   micro avg       0.55      0.55      0.55       674\n   macro avg       0.49      0.49      0.48       674\nweighted avg       0.51      0.55      0.52       674\n\n('T:', '6.952913284301758')\n('Epoch num - ', 0, ' and batch num ', 2)\n(0.6806106567382812,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.63      0.72      0.68       424\n           1       0.38      0.29      0.33       250\n\n   micro avg       0.56      0.56      0.56       674\n   macro avg       0.51      0.51      0.50       674\nweighted avg       0.54      0.56      0.55       674\n\n('T:', '6.601180791854858')\n('Epoch num - ', 0, ' and batch num ', 3)\n(0.6755014061927795,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.60      0.78      0.68       389\n           1       0.49      0.29      0.37       285\n\n   micro avg       0.57      0.57      0.57       674\n   macro avg       0.55      0.54      0.52       674\nweighted avg       0.55      0.57      0.55       674\n\n('T:', '6.832984924316406')\n('Epoch num - ', 0, ' and batch num ', 4)\n(0.7006281614303589,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.62      0.81      0.70       395\n           1       0.52      0.29      0.37       279\n\n   micro avg       0.59      0.59      0.59       674\n   macro avg       0.57      0.55      0.54       674\nweighted avg       0.58      0.59      0.56       674\n\n('T:', '7.1090781688690186')\n('Epoch num - ', 0, ' and batch num ', 5)\n(0.6611982583999634,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.62      0.81      0.70       400\n           1       0.50      0.28      0.36       274\n\n   micro avg       0.59      0.59      0.59       674\n   macro avg       0.56      0.54      0.53       674\nweighted avg       0.57      0.59      0.56       674\n\n('T:', '6.810832500457764')\n('Epoch num - ', 0, ' and batch num ', 6)\n(0.6773045659065247,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.65      0.85      0.74       417\n           1       0.52      0.26      0.35       257\n\n   micro avg       0.63      0.63      0.63       674\n   macro avg       0.59      0.56      0.54       674\nweighted avg       0.60      0.63      0.59       674\n\n('T:', '6.546205282211304')\n('Epoch num - ', 0, ' and batch num ', 7)\n(0.64801424741745,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.66      0.85      0.75       418\n           1       0.55      0.29      0.38       256\n\n   micro avg       0.64      0.64      0.64       674\n   macro avg       0.61      0.57      0.56       674\nweighted avg       0.62      0.64      0.61       674\n\n('T:', '6.789651155471802')\n('Epoch num - ', 0, ' and batch num ', 8)\n(0.6398927569389343,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.67      0.88      0.76       417\n           1       0.62      0.31      0.41       257\n\n   micro avg       0.66      0.66      0.66       674\n   macro avg       0.65      0.59      0.59       674\nweighted avg       0.65      0.66      0.63       674\n\n('T:', '6.7714433670043945')\n('Epoch num - ', 0, ' and batch num ', 9)\n(0.6284846067428589,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.62      0.84      0.71       394\n           1       0.55      0.28      0.37       280\n\n   micro avg       0.61      0.61      0.61       674\n   macro avg       0.59      0.56      0.54       674\nweighted avg       0.59      0.61      0.57       674\n\n('T:', '6.94097375869751')\n('Epoch num - ', 0, ' and batch num ', 10)\n(0.656950831413269,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.66      0.87      0.75       625\n           1       0.59      0.30      0.39       392\n\n   micro avg       0.65      0.65      0.65      1017\n   macro avg       0.63      0.58      0.57      1017\nweighted avg       0.64      0.65      0.62      1017\n\n('T:', '4.139064311981201')\n(0.6225986480712891,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.67      0.88      0.76       414\n           1       0.63      0.32      0.43       260\n\n   micro avg       0.66      0.66      0.66       674\n   macro avg       0.65      0.60      0.59       674\nweighted avg       0.66      0.66      0.63       674\n\n('T:', '7.2590906620025635')\n('Epoch num - ', 0, ' and batch num ', 11)\n(0.6271389722824097,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.67      0.88      0.76       415\n           1       0.62      0.32      0.42       259\n\n   micro avg       0.66      0.66      0.66       674\n   macro avg       0.65      0.60      0.59       674\nweighted avg       0.65      0.66      0.63       674\n\n('T:', '6.8921263217926025')\n('Epoch num - ', 0, ' and batch num ', 12)\n(0.618722140789032,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.68      0.89      0.77       421\n           1       0.63      0.30      0.41       253\n\n   micro avg       0.67      0.67      0.67       674\n   macro avg       0.66      0.60      0.59       674\nweighted avg       0.66      0.67      0.64       674\n\n('T:', '7.096509218215942')\n('Epoch num - ', 0, ' and batch num ', 13)\n(0.6134195923805237,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.63      0.87      0.73       393\n           1       0.62      0.29      0.39       281\n\n   micro avg       0.63      0.63      0.63       674\n   macro avg       0.62      0.58      0.56       674\nweighted avg       0.63      0.63      0.59       674\n\n('T:', '6.785639762878418')\n('Epoch num - ', 0, ' and batch num ', 14)\n(0.6369413733482361,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.68      0.89      0.77       413\n           1       0.65      0.34      0.45       261\n\n   micro avg       0.68      0.68      0.68       674\n   macro avg       0.67      0.61      0.61       674\nweighted avg       0.67      0.68      0.65       674\n\n('T:', '6.835196495056152')\n('Epoch num - ', 0, ' and batch num ', 15)\n(0.5990637540817261,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.64      0.90      0.75       394\n           1       0.68      0.29      0.41       280\n\n   micro avg       0.65      0.65      0.65       674\n   macro avg       0.66      0.60      0.58       674\nweighted avg       0.66      0.65      0.61       674\n\n('T:', '6.832140207290649')\n('Epoch num - ', 0, ' and batch num ', 16)\n(0.617526650428772,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.68      0.90      0.77       402\n           1       0.71      0.38      0.49       272\n\n   micro avg       0.69      0.69      0.69       674\n   macro avg       0.70      0.64      0.63       674\nweighted avg       0.69      0.69      0.66       674\n\n('T:', '6.756030797958374')\n('Epoch num - ', 0, ' and batch num ', 17)\n(0.5916371941566467,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.63      0.91      0.74       368\n           1       0.76      0.35      0.48       306\n\n   micro avg       0.65      0.65      0.65       674\n   macro avg       0.69      0.63      0.61       674\nweighted avg       0.69      0.65      0.62       674\n\n('T:', '8.130068063735962')\n('Epoch num - ', 0, ' and batch num ', 18)\n(0.6194534301757812,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.66      0.90      0.76       397\n           1       0.69      0.33      0.44       277\n\n   micro avg       0.66      0.66      0.66       674\n   macro avg       0.67      0.61      0.60       674\nweighted avg       0.67      0.66      0.63       674\n\n('T:', '6.8423614501953125')\n('Epoch num - ', 0, ' and batch num ', 19)\n(0.5858557224273682,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.68      0.88      0.77       410\n           1       0.65      0.35      0.45       264\n\n   micro avg       0.67      0.67      0.67       674\n   macro avg       0.66      0.61      0.61       674\nweighted avg       0.67      0.67      0.64       674\n\n('T:', '6.669337034225464')\n('Epoch num - ', 0, ' and batch num ', 20)\n(0.5913493037223816,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.69      0.88      0.78       625\n           1       0.67      0.38      0.48       392\n\n   micro avg       0.69      0.69      0.69      1017\n   macro avg       0.68      0.63      0.63      1017\nweighted avg       0.69      0.69      0.66      1017\n\n('T:', '4.069922208786011')\n(0.5831820964813232,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.71      0.89      0.79       418\n           1       0.70      0.41      0.51       256\n\n   micro avg       0.71      0.71      0.71       674\n   macro avg       0.70      0.65      0.65       674\nweighted avg       0.71      0.71      0.69       674\n\n('T:', '6.902959823608398')\n('Epoch num - ', 0, ' and batch num ', 21)\n(0.5742017030715942,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.70      0.91      0.79       407\n           1       0.75      0.39      0.51       267\n\n   micro avg       0.71      0.71      0.71       674\n   macro avg       0.72      0.65      0.65       674\nweighted avg       0.72      0.71      0.68       674\n\n('T:', '6.632169723510742')\n('Epoch num - ', 0, ' and batch num ', 22)\n(0.5888328552246094,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.71      0.91      0.80       400\n           1       0.77      0.46      0.58       274\n\n   micro avg       0.73      0.73      0.73       674\n   macro avg       0.74      0.68      0.69       674\nweighted avg       0.73      0.73      0.71       674\n\n('T:', '7.0727643966674805')\n('Epoch num - ', 0, ' and batch num ', 23)\n(0.5672476291656494,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.69      0.87      0.77       399\n           1       0.70      0.42      0.52       275\n\n   micro avg       0.69      0.69      0.69       674\n   macro avg       0.69      0.65      0.65       674\nweighted avg       0.69      0.69      0.67       674\n\n('T:', '6.647812604904175')\n('Epoch num - ', 0, ' and batch num ', 24)\n(0.5930498838424683,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.66      0.89      0.76       378\n           1       0.75      0.43      0.55       296\n\n   micro avg       0.69      0.69      0.69       674\n   macro avg       0.71      0.66      0.65       674\nweighted avg       0.70      0.69      0.67       674\n\n('T:', '6.845412254333496')\n('Epoch num - ', 0, ' and batch num ', 25)\n(0.5877396464347839,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.71      0.87      0.78       411\n           1       0.69      0.45      0.54       263\n\n   micro avg       0.71      0.71      0.71       674\n   macro avg       0.70      0.66      0.66       674\nweighted avg       0.70      0.71      0.69       674\n\n('T:', '6.843246221542358')\n('Epoch num - ', 0, ' and batch num ', 26)\n(0.5856401324272156,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.72      0.86      0.79       413\n           1       0.69      0.47      0.56       261\n\n   micro avg       0.71      0.71      0.71       674\n   macro avg       0.70      0.67      0.67       674\nweighted avg       0.71      0.71      0.70       674\n\n('T:', '6.696251630783081')\n('Epoch num - ', 0, ' and batch num ', 27)\n(0.5608684420585632,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.72      0.87      0.79       405\n           1       0.72      0.49      0.58       269\n\n   micro avg       0.72      0.72      0.72       674\n   macro avg       0.72      0.68      0.69       674\nweighted avg       0.72      0.72      0.71       674\n\n('T:', '7.018646001815796')\n('Epoch num - ', 0, ' and batch num ', 28)\n(0.5505573749542236,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.72      0.85      0.78       415\n           1       0.66      0.46      0.55       259\n\n   micro avg       0.70      0.70      0.70       674\n   macro avg       0.69      0.66      0.66       674\nweighted avg       0.70      0.70      0.69       674\n\n('T:', '6.498310327529907')\n('Epoch num - ', 0, ' and batch num ', 29)\n(0.5662465691566467,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.72      0.86      0.78       411\n           1       0.69      0.48      0.57       263\n\n   micro avg       0.71      0.71      0.71       674\n   macro avg       0.70      0.67      0.68       674\nweighted avg       0.71      0.71      0.70       674\n\n('T:', '6.7266526222229')\n('Epoch num - ', 0, ' and batch num ', 30)\n(0.5685308575630188,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.73      0.86      0.79       625\n           1       0.69      0.51      0.58       392\n\n   micro avg       0.72      0.72      0.72      1017\n   macro avg       0.71      0.68      0.69      1017\nweighted avg       0.72      0.72      0.71      1017\n\n('T:', '4.037211894989014')\n(0.5408914089202881,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.74      0.90      0.81       402\n           1       0.78      0.53      0.63       272\n\n   micro avg       0.75      0.75      0.75       674\n   macro avg       0.76      0.72      0.72       674\nweighted avg       0.76      0.75      0.74       674\n\n('T:', '6.588239431381226')\n('Epoch num - ', 0, ' and batch num ', 31)\n(0.523691713809967,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.71      0.87      0.78       387\n           1       0.74      0.52      0.61       287\n\n   micro avg       0.72      0.72      0.72       674\n   macro avg       0.73      0.69      0.70       674\nweighted avg       0.72      0.72      0.71       674\n\n('T:', '6.9895570278167725')\n('Epoch num - ', 0, ' and batch num ', 32)\n(0.5428921580314636,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.75      0.87      0.81       413\n           1       0.73      0.54      0.62       261\n\n   micro avg       0.74      0.74      0.74       674\n   macro avg       0.74      0.71      0.71       674\nweighted avg       0.74      0.74      0.74       674\n\n('T:', '7.048943758010864')\n('Epoch num - ', 0, ' and batch num ', 33)\n(0.5138651132583618,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.73      0.84      0.78       402\n           1       0.70      0.54      0.61       272\n\n   micro avg       0.72      0.72      0.72       674\n   macro avg       0.72      0.69      0.70       674\nweighted avg       0.72      0.72      0.71       674\n\n('T:', '7.621331453323364')\n('Epoch num - ', 0, ' and batch num ', 34)\n(0.5475116968154907,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.74      0.88      0.80       391\n           1       0.77      0.56      0.65       283\n\n   micro avg       0.75      0.75      0.75       674\n   macro avg       0.75      0.72      0.73       674\nweighted avg       0.75      0.75      0.74       674\n\n('T:', '6.932114839553833')\n('Epoch num - ', 0, ' and batch num ', 35)\n(0.5230617523193359,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.75      0.85      0.80       407\n           1       0.71      0.57      0.63       267\n\n   micro avg       0.74      0.74      0.74       674\n   macro avg       0.73      0.71      0.72       674\nweighted avg       0.74      0.74      0.73       674\n\n('T:', '6.933541536331177')\n('Epoch num - ', 0, ' and batch num ', 36)\n(0.5361081957817078,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.75      0.86      0.80       392\n           1       0.76      0.61      0.68       282\n\n   micro avg       0.76      0.76      0.76       674\n   macro avg       0.76      0.74      0.74       674\nweighted avg       0.76      0.76      0.75       674\n\n('T:', '7.123108863830566')\n('Epoch num - ', 0, ' and batch num ', 37)\n(0.4767593741416931,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.78      0.84      0.81       415\n           1       0.71      0.63      0.66       259\n\n   micro avg       0.76      0.76      0.76       674\n   macro avg       0.74      0.73      0.74       674\nweighted avg       0.75      0.76      0.75       674\n\n('T:', '6.898891925811768')\n('Epoch num - ', 0, ' and batch num ', 38)\n(0.4978736340999603,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.74      0.82      0.78       406\n           1       0.67      0.56      0.61       268\n\n   micro avg       0.72      0.72      0.72       674\n   macro avg       0.71      0.69      0.70       674\nweighted avg       0.71      0.72      0.71       674\n\n('T:', '6.819106817245483')\n('Epoch num - ', 0, ' and batch num ', 39)\n(0.541763186454773,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.80      0.87      0.83       411\n           1       0.76      0.66      0.70       263\n\n   micro avg       0.78      0.78      0.78       674\n   macro avg       0.78      0.76      0.77       674\nweighted avg       0.78      0.78      0.78       674\n\n('T:', '6.743719577789307')\n('Epoch num - ', 0, ' and batch num ', 40)\n(0.4625784456729889,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.77      0.83      0.80       625\n           1       0.69      0.61      0.65       392\n\n   micro avg       0.75      0.75      0.75      1017\n   macro avg       0.73      0.72      0.73      1017\nweighted avg       0.74      0.75      0.74      1017\n\n('T:', '4.099848747253418')\n(0.5103756189346313,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.79      0.83      0.81       407\n           1       0.72      0.67      0.70       267\n\n   micro avg       0.77      0.77      0.77       674\n   macro avg       0.76      0.75      0.75       674\nweighted avg       0.77      0.77      0.77       674\n\n('T:', '6.92943549156189')\n('Epoch num - ', 0, ' and batch num ', 41)\n(0.49490392208099365,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.78      0.81      0.80       406\n           1       0.70      0.66      0.68       268\n\n   micro avg       0.75      0.75      0.75       674\n   macro avg       0.74      0.74      0.74       674\nweighted avg       0.75      0.75      0.75       674\n\n('T:', '6.704693555831909')\n('Epoch num - ', 0, ' and batch num ', 42)\n(0.5022077560424805,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.77      0.81      0.79       399\n           1       0.70      0.66      0.68       275\n\n   micro avg       0.75      0.75      0.75       674\n   macro avg       0.74      0.73      0.74       674\nweighted avg       0.75      0.75      0.75       674\n\n('T:', '6.578879356384277')\n('Epoch num - ', 0, ' and batch num ', 43)\n(0.535820484161377,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.77      0.80      0.78       395\n           1       0.70      0.66      0.68       279\n\n   micro avg       0.74      0.74      0.74       674\n   macro avg       0.73      0.73      0.73       674\nweighted avg       0.74      0.74      0.74       674\n\n('T:', '6.642465829849243')\n('Epoch num - ', 0, ' and batch num ', 44)\n(0.5095057487487793,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.79      0.82      0.80       393\n           1       0.73      0.69      0.71       281\n\n   micro avg       0.77      0.77      0.77       674\n   macro avg       0.76      0.76      0.76       674\nweighted avg       0.77      0.77      0.77       674\n\n('T:', '6.424683332443237')\n('Epoch num - ', 0, ' and batch num ', 45)\n(0.48444196581840515,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.78      0.79      0.79       404\n           1       0.68      0.67      0.68       270\n\n   micro avg       0.74      0.74      0.74       674\n   macro avg       0.73      0.73      0.73       674\nweighted avg       0.74      0.74      0.74       674\n\n('T:', '7.0909435749053955')\n('Epoch num - ', 0, ' and batch num ', 46)\n(0.5013421177864075,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.78      0.80      0.79       393\n           1       0.71      0.68      0.69       281\n\n   micro avg       0.75      0.75      0.75       674\n   macro avg       0.74      0.74      0.74       674\nweighted avg       0.75      0.75      0.75       674\n\n('T:', '7.11698317527771')\n('Epoch num - ', 0, ' and batch num ', 47)\n(0.5139281749725342,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.83      0.79      0.81       416\n           1       0.68      0.73      0.71       258\n\n   micro avg       0.77      0.77      0.77       674\n   macro avg       0.75      0.76      0.76       674\nweighted avg       0.77      0.77      0.77       674\n\n('T:', '6.62750768661499')\n('Epoch num - ', 0, ' and batch num ', 48)\n(0.5068700313568115,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.83      0.82      0.82       408\n           1       0.73      0.74      0.73       266\n\n   micro avg       0.79      0.79      0.79       674\n   macro avg       0.78      0.78      0.78       674\nweighted avg       0.79      0.79      0.79       674\n\n('T:', '6.697550058364868')\n('Epoch num - ', 0, ' and batch num ', 49)\n(0.4816039204597473,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.82      0.80      0.81       398\n           1       0.72      0.74      0.73       276\n\n   micro avg       0.78      0.78      0.78       674\n   macro avg       0.77      0.77      0.77       674\nweighted avg       0.78      0.78      0.78       674\n\n('T:', '6.723927736282349')\n('Epoch num - ', 0, ' and batch num ', 50)\n(0.48271429538726807,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.83      0.78      0.80       625\n           1       0.68      0.74      0.71       392\n\n   micro avg       0.76      0.76      0.76      1017\n   macro avg       0.75      0.76      0.76      1017\nweighted avg       0.77      0.76      0.77      1017\n\n('T:', '4.056748390197754')\n(0.47845399379730225,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.82      0.77      0.79       413\n           1       0.67      0.74      0.70       261\n\n   micro avg       0.76      0.76      0.76       674\n   macro avg       0.74      0.75      0.75       674\nweighted avg       0.76      0.76      0.76       674\n\n('T:', '6.854792594909668')\n('Epoch num - ', 0, ' and batch num ', 51)\n(0.48480379581451416,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.78      0.81       425\n           1       0.67      0.75      0.71       249\n\n   micro avg       0.77      0.77      0.77       674\n   macro avg       0.76      0.77      0.76       674\nweighted avg       0.78      0.77      0.77       674\n\n('T:', '6.664443731307983')\n('Epoch num - ', 0, ' and batch num ', 52)\n(0.47479695081710815,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.76      0.80       429\n           1       0.64      0.76      0.69       245\n\n   micro avg       0.76      0.76      0.76       674\n   macro avg       0.74      0.76      0.75       674\nweighted avg       0.77      0.76      0.76       674\n\n('T:', '6.646332263946533')\n('Epoch num - ', 0, ' and batch num ', 53)\n(0.5003140568733215,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.77      0.81       412\n           1       0.69      0.79      0.74       262\n\n   micro avg       0.78      0.78      0.78       674\n   macro avg       0.77      0.78      0.77       674\nweighted avg       0.79      0.78      0.78       674\n\n('T:', '6.73206090927124')\n('Epoch num - ', 0, ' and batch num ', 54)\n(0.46768179535865784,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.76      0.82       449\n           1       0.63      0.81      0.71       225\n\n   micro avg       0.78      0.78      0.78       674\n   macro avg       0.76      0.79      0.76       674\nweighted avg       0.80      0.78      0.78       674\n\n('T:', '6.859065294265747')\n('Epoch num - ', 0, ' and batch num ', 55)\n(0.5025045871734619,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.80      0.82       397\n           1       0.73      0.77      0.75       277\n\n   micro avg       0.79      0.79      0.79       674\n   macro avg       0.78      0.79      0.79       674\nweighted avg       0.79      0.79      0.79       674\n\n('T:', '7.001025199890137')\n('Epoch num - ', 0, ' and batch num ', 56)\n(0.4773833155632019,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.78      0.82       418\n           1       0.69      0.79      0.73       256\n\n   micro avg       0.78      0.78      0.78       674\n   macro avg       0.77      0.78      0.78       674\nweighted avg       0.79      0.78      0.79       674\n\n('T:', '6.7966413497924805')\n('Epoch num - ', 0, ' and batch num ', 57)\n(0.4517923593521118,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.79      0.82       413\n           1       0.70      0.79      0.74       261\n\n   micro avg       0.79      0.79      0.79       674\n   macro avg       0.78      0.79      0.78       674\nweighted avg       0.79      0.79      0.79       674\n\n('T:', '7.587969064712524')\n('Epoch num - ', 0, ' and batch num ', 58)\n(0.47093915939331055,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.79      0.81       402\n           1       0.71      0.79      0.75       272\n\n   micro avg       0.79      0.79      0.79       674\n   macro avg       0.78      0.79      0.78       674\nweighted avg       0.79      0.79      0.79       674\n\n('T:', '6.7692718505859375')\n('Epoch num - ', 0, ' and batch num ', 59)\n(0.46647948026657104,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.79      0.82       419\n           1       0.69      0.78      0.73       255\n\n   micro avg       0.78      0.78      0.78       674\n   macro avg       0.77      0.78      0.78       674\nweighted avg       0.79      0.78      0.79       674\n\n('T:', '6.724809408187866')\n('Epoch num - ', 0, ' and batch num ', 60)\n(0.44361844658851624,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.78      0.82       625\n           1       0.69      0.79      0.74       392\n\n   micro avg       0.78      0.78      0.78      1017\n   macro avg       0.77      0.79      0.78      1017\nweighted avg       0.79      0.78      0.79      1017\n\n('T:', '4.095785140991211')\n(0.4661751091480255,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.81      0.83       392\n           1       0.75      0.79      0.77       282\n\n   micro avg       0.80      0.80      0.80       674\n   macro avg       0.80      0.80      0.80       674\nweighted avg       0.80      0.80      0.80       674\n\n('T:', '6.766419172286987')\n('Epoch num - ', 0, ' and batch num ', 61)\n(0.43752920627593994,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.79      0.82       398\n           1       0.72      0.80      0.76       276\n\n   micro avg       0.79      0.79      0.79       674\n   macro avg       0.79      0.80      0.79       674\nweighted avg       0.80      0.79      0.80       674\n\n('T:', '7.031902313232422')\n('Epoch num - ', 0, ' and batch num ', 62)\n(0.45744967460632324,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.79      0.82       389\n           1       0.74      0.81      0.77       285\n\n   micro avg       0.80      0.80      0.80       674\n   macro avg       0.79      0.80      0.80       674\nweighted avg       0.80      0.80      0.80       674\n\n('T:', '7.100852966308594')\n('Epoch num - ', 0, ' and batch num ', 63)\n(0.4689772129058838,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.75      0.80       411\n           1       0.68      0.82      0.74       263\n\n   micro avg       0.78      0.78      0.78       674\n   macro avg       0.77      0.78      0.77       674\nweighted avg       0.79      0.78      0.78       674\n\n('T:', '6.842680215835571')\n('Epoch num - ', 0, ' and batch num ', 64)\n(0.4709722101688385,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.79      0.83       391\n           1       0.74      0.82      0.78       283\n\n   micro avg       0.81      0.81      0.81       674\n   macro avg       0.80      0.81      0.80       674\nweighted avg       0.81      0.81      0.81       674\n\n('T:', '6.934786319732666')\n('Epoch num - ', 0, ' and batch num ', 65)\n(0.42322131991386414,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.86      0.81      0.84       382\n           1       0.77      0.83      0.80       292\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.82      0.82      0.82       674\nweighted avg       0.82      0.82      0.82       674\n\n('T:', '6.981743335723877')\n('Epoch num - ', 0, ' and batch num ', 66)\n(0.44973400235176086,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.74      0.82       429\n           1       0.66      0.87      0.75       245\n\n   micro avg       0.79      0.79      0.79       674\n   macro avg       0.78      0.80      0.78       674\nweighted avg       0.82      0.79      0.79       674\n\n('T:', '6.620385646820068')\n('Epoch num - ', 0, ' and batch num ', 67)\n(0.42768269777297974,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.77      0.81       399\n           1       0.71      0.79      0.75       275\n\n   micro avg       0.78      0.78      0.78       674\n   macro avg       0.77      0.78      0.78       674\nweighted avg       0.79      0.78      0.78       674\n\n('T:', '6.77873969078064')\n('Epoch num - ', 0, ' and batch num ', 68)\n(0.47466424107551575,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.78      0.83       408\n           1       0.71      0.85      0.78       266\n\n   micro avg       0.81      0.81      0.81       674\n   macro avg       0.80      0.81      0.80       674\nweighted avg       0.82      0.81      0.81       674\n\n('T:', '6.958028793334961')\n('Epoch num - ', 0, ' and batch num ', 69)\n(0.41495734453201294,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.80      0.84       401\n           1       0.74      0.86      0.80       273\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.82      0.83      0.82       674\nweighted avg       0.83      0.82      0.83       674\n\n('T:', '6.654832363128662')\n('Epoch num - ', 0, ' and batch num ', 70)\n(0.4126036763191223,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.78      0.83       625\n           1       0.71      0.85      0.77       392\n\n   micro avg       0.81      0.81      0.81      1017\n   macro avg       0.80      0.81      0.80      1017\nweighted avg       0.82      0.81      0.81      1017\n\n('T:', '4.059913158416748')\n(0.4226857125759125,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.78      0.83       416\n           1       0.70      0.84      0.77       258\n\n   micro avg       0.80      0.80      0.80       674\n   macro avg       0.80      0.81      0.80       674\nweighted avg       0.82      0.80      0.81       674\n\n('T:', '6.410089015960693')\n('Epoch num - ', 0, ' and batch num ', 71)\n(0.43386581540107727,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.77      0.82       407\n           1       0.70      0.84      0.76       267\n\n   micro avg       0.80      0.80      0.80       674\n   macro avg       0.79      0.80      0.79       674\nweighted avg       0.81      0.80      0.80       674\n\n('T:', '6.6749794483184814')\n('Epoch num - ', 0, ' and batch num ', 72)\n(0.43540510535240173,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.80      0.83       397\n           1       0.74      0.82      0.78       277\n\n   micro avg       0.81      0.81      0.81       674\n   macro avg       0.80      0.81      0.80       674\nweighted avg       0.81      0.81      0.81       674\n\n('T:', '6.615496873855591')\n('Epoch num - ', 0, ' and batch num ', 73)\n(0.43349283933639526,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.79      0.84       417\n           1       0.71      0.86      0.78       257\n\n   micro avg       0.81      0.81      0.81       674\n   macro avg       0.81      0.82      0.81       674\nweighted avg       0.83      0.81      0.82       674\n\n('T:', '6.900478839874268')\n('Epoch num - ', 0, ' and batch num ', 74)\n(0.3993746340274811,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.78      0.83       398\n           1       0.73      0.86      0.79       276\n\n   micro avg       0.81      0.81      0.81       674\n   macro avg       0.81      0.82      0.81       674\nweighted avg       0.82      0.81      0.81       674\n\n('T:', '6.580112934112549')\n('Epoch num - ', 0, ' and batch num ', 75)\n(0.4195038080215454,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.84      0.85       376\n           1       0.80      0.81      0.81       298\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.83      0.83      0.83       674\nweighted avg       0.83      0.83      0.83       674\n\n('T:', '6.783588886260986')\n('Epoch num - ', 0, ' and batch num ', 76)\n(0.41093045473098755,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.80      0.85       410\n           1       0.73      0.88      0.80       264\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.82      0.84      0.82       674\nweighted avg       0.84      0.83      0.83       674\n\n('T:', '6.982311964035034')\n('Epoch num - ', 0, ' and batch num ', 77)\n(0.40130099654197693,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.80      0.84       423\n           1       0.71      0.81      0.76       251\n\n   micro avg       0.81      0.81      0.81       674\n   macro avg       0.79      0.81      0.80       674\nweighted avg       0.82      0.81      0.81       674\n\n('T:', '6.6718666553497314')\n('Epoch num - ', 0, ' and batch num ', 78)\n(0.4243701994419098,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.83      0.85       389\n           1       0.78      0.83      0.81       285\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.83      0.83      0.83       674\nweighted avg       0.83      0.83      0.83       674\n\n('T:', '6.970106363296509')\n('Epoch num - ', 0, ' and batch num ', 79)\n(0.405254065990448,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.83      0.85       401\n           1       0.77      0.84      0.80       273\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.82      0.83      0.83       674\nweighted avg       0.83      0.83      0.83       674\n\n('T:', '6.804699659347534')\n('Epoch num - ', 0, ' and batch num ', 80)\n(0.3814516067504883,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.81      0.85       625\n           1       0.73      0.85      0.79       392\n\n   micro avg       0.82      0.82      0.82      1017\n   macro avg       0.82      0.83      0.82      1017\nweighted avg       0.84      0.82      0.83      1017\n\n('T:', '4.025796890258789')\n(0.39096853137016296,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.82      0.86       415\n           1       0.75      0.86      0.80       259\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.84      0.83       674\nweighted avg       0.85      0.84      0.84       674\n\n('T:', '7.017197608947754')\n('Epoch num - ', 0, ' and batch num ', 81)\n(0.39823174476623535,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.85      0.82      0.84       388\n           1       0.77      0.80      0.79       286\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.81      0.81      0.81       674\nweighted avg       0.82      0.82      0.82       674\n\n('T:', '7.149710655212402')\n('Epoch num - ', 0, ' and batch num ', 82)\n(0.42036715149879456,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.79      0.83       418\n           1       0.70      0.81      0.75       256\n\n   micro avg       0.80      0.80      0.80       674\n   macro avg       0.79      0.80      0.79       674\nweighted avg       0.81      0.80      0.80       674\n\n('T:', '6.566035032272339')\n('Epoch num - ', 0, ' and batch num ', 83)\n(0.4589555263519287,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.84      0.87       409\n           1       0.77      0.86      0.81       265\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.85      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '7.277384996414185')\n('Epoch num - ', 0, ' and batch num ', 84)\n(0.3972562849521637,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.84      0.86       406\n           1       0.77      0.84      0.81       268\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.84      0.84       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.803306341171265')\n('Epoch num - ', 0, ' and batch num ', 85)\n(0.37245795130729675,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.82      0.84       416\n           1       0.73      0.78      0.75       258\n\n   micro avg       0.80      0.80      0.80       674\n   macro avg       0.79      0.80      0.80       674\nweighted avg       0.81      0.80      0.81       674\n\n('T:', '6.662121295928955')\n('Epoch num - ', 0, ' and batch num ', 86)\n(0.4305391311645508,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.82      0.85       398\n           1       0.76      0.85      0.80       276\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.83      0.83      0.83       674\nweighted avg       0.84      0.83      0.83       674\n\n('T:', '6.85004186630249')\n('Epoch num - ', 0, ' and batch num ', 87)\n(0.3903537690639496,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.86      0.86       395\n           1       0.80      0.82      0.81       279\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.84      0.84      0.84       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.893625020980835')\n('Epoch num - ', 0, ' and batch num ', 88)\n(0.38134288787841797,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.83      0.85       423\n           1       0.74      0.80      0.77       251\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.81      0.82      0.81       674\nweighted avg       0.83      0.82      0.82       674\n\n('T:', '6.534217834472656')\n('Epoch num - ', 0, ' and batch num ', 89)\n(0.40175861120224,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.85      0.86       405\n           1       0.78      0.81      0.79       269\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.83      0.83      0.83       674\nweighted avg       0.83      0.83      0.83       674\n\n('T:', '6.70500636100769')\n('Epoch num - ', 0, ' and batch num ', 90)\n(0.39852797985076904,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.84      0.85       625\n           1       0.76      0.80      0.78       392\n\n   micro avg       0.82      0.82      0.82      1017\n   macro avg       0.81      0.82      0.82      1017\nweighted avg       0.83      0.82      0.82      1017\n\n('T:', '4.045736789703369')\n(0.37973618507385254,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.84      0.85       410\n           1       0.76      0.80      0.78       264\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.81      0.82      0.81       674\nweighted avg       0.82      0.82      0.82       674\n\n('T:', '6.6130475997924805')\n('Epoch num - ', 0, ' and batch num ', 91)\n(0.37734293937683105,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.84      0.86       393\n           1       0.79      0.83      0.81       281\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.84      0.83       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '7.061568021774292')\n('Epoch num - ', 0, ' and batch num ', 92)\n(0.36251577734947205,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.85      0.86       410\n           1       0.78      0.82      0.80       264\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.83      0.83       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '7.078660249710083')\n('Epoch num - ', 0, ' and batch num ', 93)\n(0.3710373640060425,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.85      0.87       413\n           1       0.78      0.83      0.80       261\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.84      0.83       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '7.004984140396118')\n('Epoch num - ', 0, ' and batch num ', 94)\n(0.37404346466064453,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.85      0.85       412\n           1       0.77      0.77      0.77       262\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.81      0.81      0.81       674\nweighted avg       0.82      0.82      0.82       674\n\n('T:', '6.907012224197388')\n('Epoch num - ', 0, ' and batch num ', 95)\n(0.40894871950149536,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.84      0.85       407\n           1       0.77      0.79      0.78       267\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.81      0.81      0.81       674\nweighted avg       0.82      0.82      0.82       674\n\n('T:', '6.878199815750122')\n('Epoch num - ', 0, ' and batch num ', 96)\n(0.39318135380744934,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.88      0.86       405\n           1       0.80      0.75      0.78       269\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.82      0.81      0.82       674\nweighted avg       0.83      0.83      0.83       674\n\n('T:', '13.74344277381897')\n('Epoch num - ', 0, ' and batch num ', 97)\n(0.4015245735645294,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.86      0.87       433\n           1       0.76      0.78      0.77       241\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.82      0.82      0.82       674\nweighted avg       0.83      0.83      0.83       674\n\n('T:', '7.003515958786011')\n('Epoch num - ', 0, ' and batch num ', 98)\n(0.41005608439445496,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.82      0.90      0.85       400\n           1       0.82      0.71      0.76       274\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.82      0.80      0.81       674\nweighted avg       0.82      0.82      0.82       674\n\n('T:', '6.64970850944519')\n('Epoch num - ', 0, ' and batch num ', 99)\n(0.4173722565174103,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.88      0.87       406\n           1       0.81      0.79      0.80       268\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.84      0.83      0.83       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.522793292999268')\n('Epoch num - ', 0, ' and batch num ', 100)\n(0.4217158555984497,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.87      0.85       625\n           1       0.77      0.73      0.75       392\n\n   micro avg       0.81      0.81      0.81      1017\n   macro avg       0.80      0.80      0.80      1017\nweighted avg       0.81      0.81      0.81      1017\n\n('T:', '4.212064743041992')\n(0.4071532189846039,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.89      0.87       418\n           1       0.80      0.74      0.77       256\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.82      0.81      0.82       674\nweighted avg       0.83      0.83      0.83       674\n\n('T:', '6.84573769569397')\n('Epoch num - ', 0, ' and batch num ', 101)\n(0.40086981654167175,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.90      0.87       421\n           1       0.81      0.74      0.77       253\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.82      0.82       674\nweighted avg       0.83      0.84      0.83       674\n\n('T:', '6.832534074783325')\n('Epoch num - ', 0, ' and batch num ', 102)\n(0.38884618878364563,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.82      0.89      0.85       403\n           1       0.81      0.71      0.75       271\n\n   micro avg       0.81      0.81      0.81       674\n   macro avg       0.81      0.80      0.80       674\nweighted avg       0.81      0.81      0.81       674\n\n('T:', '6.737389326095581')\n('Epoch num - ', 0, ' and batch num ', 103)\n(0.42855721712112427,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.89      0.86       414\n           1       0.81      0.73      0.77       260\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.82      0.81      0.82       674\nweighted avg       0.83      0.83      0.83       674\n\n('T:', '6.952444314956665')\n('Epoch num - ', 0, ' and batch num ', 104)\n(0.4266308844089508,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.82      0.89      0.85       400\n           1       0.81      0.71      0.76       274\n\n   micro avg       0.81      0.81      0.81       674\n   macro avg       0.81      0.80      0.80       674\nweighted avg       0.81      0.81      0.81       674\n\n('T:', '7.071681976318359')\n('Epoch num - ', 0, ' and batch num ', 105)\n(0.43822118639945984,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.86      0.85       429\n           1       0.75      0.73      0.74       245\n\n   micro avg       0.81      0.81      0.81       674\n   macro avg       0.80      0.79      0.80       674\nweighted avg       0.81      0.81      0.81       674\n\n('T:', '6.829620599746704')\n('Epoch num - ', 0, ' and batch num ', 106)\n(0.3952270448207855,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.91      0.88       413\n           1       0.84      0.77      0.80       261\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.84      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.841744422912598')\n('Epoch num - ', 0, ' and batch num ', 107)\n(0.39265531301498413,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.82      0.91      0.87       393\n           1       0.85      0.73      0.79       281\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.84      0.82      0.83       674\nweighted avg       0.84      0.84      0.83       674\n\n('T:', '7.171774864196777')\n('Epoch num - ', 0, ' and batch num ', 108)\n(0.40367621183395386,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.83      0.89      0.86       404\n           1       0.82      0.72      0.77       270\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.82      0.81      0.81       674\nweighted avg       0.82      0.82      0.82       674\n\n('T:', '7.765240907669067')\n('Epoch num - ', 0, ' and batch num ', 109)\n(0.4279564619064331,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.82      0.90      0.86       387\n           1       0.85      0.73      0.78       287\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.83      0.82      0.82       674\nweighted avg       0.83      0.83      0.83       674\n\n('T:', '6.743974924087524')\n('Epoch num - ', 0, ' and batch num ', 110)\n(0.42921656370162964,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.83      0.88      0.86       625\n           1       0.79      0.72      0.76       392\n\n   micro avg       0.82      0.82      0.82      1017\n   macro avg       0.81      0.80      0.81      1017\nweighted avg       0.82      0.82      0.82      1017\n\n('T:', '4.182882785797119')\n(0.4023452699184418,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.81      0.92      0.86       386\n           1       0.87      0.72      0.79       288\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.84      0.82      0.83       674\nweighted avg       0.84      0.83      0.83       674\n\n('T:', '6.8017799854278564')\n('Epoch num - ', 0, ' and batch num ', 111)\n(0.42715317010879517,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.87      0.85       425\n           1       0.76      0.71      0.73       249\n\n   micro avg       0.81      0.81      0.81       674\n   macro avg       0.80      0.79      0.79       674\nweighted avg       0.81      0.81      0.81       674\n\n('T:', '6.683824062347412')\n('Epoch num - ', 0, ' and batch num ', 112)\n(0.43777719140052795,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.83      0.89      0.86       398\n           1       0.82      0.73      0.78       276\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.83      0.81      0.82       674\nweighted avg       0.83      0.83      0.82       674\n\n('T:', '6.870208024978638')\n('Epoch num - ', 0, ' and batch num ', 113)\n(0.4341270923614502,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.88      0.86       407\n           1       0.80      0.74      0.77       267\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.82      0.81      0.81       674\nweighted avg       0.82      0.82      0.82       674\n\n('T:', '6.709251880645752')\n('Epoch num - ', 0, ' and batch num ', 114)\n(0.42021581530570984,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.86      0.91      0.88       409\n           1       0.85      0.76      0.80       265\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.84      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.702141761779785')\n('Epoch num - ', 0, ' and batch num ', 115)\n(0.36076807975769043,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.83      0.91      0.86       393\n           1       0.85      0.73      0.79       281\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.84      0.82      0.83       674\nweighted avg       0.84      0.83      0.83       674\n\n('T:', '7.157123804092407')\n('Epoch num - ', 0, ' and batch num ', 116)\n(0.3949546813964844,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.89      0.87       413\n           1       0.82      0.77      0.79       261\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.84      0.83      0.83       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.858604907989502')\n('Epoch num - ', 0, ' and batch num ', 117)\n(0.3786848783493042,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.89      0.88       410\n           1       0.82      0.80      0.81       264\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.84      0.85       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.990755558013916')\n('Epoch num - ', 0, ' and batch num ', 118)\n(0.3670142889022827,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.86      0.86       408\n           1       0.79      0.80      0.79       266\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.83      0.83       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.66184401512146')\n('Epoch num - ', 0, ' and batch num ', 119)\n(0.38670670986175537,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.89      0.87       396\n           1       0.83      0.77      0.80       278\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.84      0.83      0.83       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.762519836425781')\n('Epoch num - ', 0, ' and batch num ', 120)\n(0.3972371816635132,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.86      0.87       625\n           1       0.79      0.82      0.81       392\n\n   micro avg       0.85      0.85      0.85      1017\n   macro avg       0.84      0.84      0.84      1017\nweighted avg       0.85      0.85      0.85      1017\n\n('T:', '4.1002037525177')\n(0.3637506663799286,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.88      0.88       410\n           1       0.81      0.81      0.81       264\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.775836229324341')\n('Epoch num - ', 0, ' and batch num ', 121)\n(0.34684646129608154,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.89      0.88       398\n           1       0.84      0.83      0.83       276\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.793186902999878')\n('Epoch num - ', 0, ' and batch num ', 122)\n(0.3582272231578827,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.87      0.89       424\n           1       0.79      0.85      0.82       250\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.9187211990356445')\n('Epoch num - ', 0, ' and batch num ', 123)\n(0.3645915687084198,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.88      0.89       397\n           1       0.83      0.86      0.85       277\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.6559672355651855')\n('Epoch num - ', 0, ' and batch num ', 124)\n(0.3565962016582489,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.88      0.89       404\n           1       0.83      0.85      0.84       270\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.87      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.909130334854126')\n('Epoch num - ', 0, ' and batch num ', 125)\n(0.3577425479888916,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.88      0.89       392\n           1       0.83      0.86      0.85       282\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.803368330001831')\n('Epoch num - ', 0, ' and batch num ', 126)\n(0.3511084318161011,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.82      0.86       413\n           1       0.75      0.85      0.80       261\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.82      0.83      0.83       674\nweighted avg       0.84      0.83      0.83       674\n\n('T:', '6.950896978378296')\n('Epoch num - ', 0, ' and batch num ', 127)\n(0.37558847665786743,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.80      0.83       391\n           1       0.75      0.82      0.78       283\n\n   micro avg       0.81      0.81      0.81       674\n   macro avg       0.80      0.81      0.81       674\nweighted avg       0.81      0.81      0.81       674\n\n('T:', '7.157407760620117')\n('Epoch num - ', 0, ' and batch num ', 128)\n(0.4437282085418701,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.81      0.85       422\n           1       0.72      0.85      0.78       252\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.81      0.83      0.81       674\nweighted avg       0.83      0.82      0.82       674\n\n('T:', '6.873577117919922')\n('Epoch num - ', 0, ' and batch num ', 129)\n(0.3856732249259949,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.81      0.84       390\n           1       0.76      0.83      0.79       284\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.81      0.82      0.81       674\nweighted avg       0.82      0.82      0.82       674\n\n('T:', '6.64910888671875')\n('Epoch num - ', 0, ' and batch num ', 130)\n(0.4042813777923584,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.81      0.85       625\n           1       0.74      0.87      0.80       392\n\n   micro avg       0.83      0.83      0.83      1017\n   macro avg       0.82      0.84      0.83      1017\nweighted avg       0.84      0.83      0.83      1017\n\n('T:', '4.0973122119903564')\n(0.3697291314601898,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.87      0.79      0.82       408\n           1       0.71      0.81      0.76       266\n\n   micro avg       0.80      0.80      0.80       674\n   macro avg       0.79      0.80      0.79       674\nweighted avg       0.81      0.80      0.80       674\n\n('T:', '6.725123167037964')\n('Epoch num - ', 0, ' and batch num ', 131)\n(0.40223756432533264,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.75      0.82       411\n           1       0.69      0.86      0.76       263\n\n   micro avg       0.79      0.79      0.79       674\n   macro avg       0.79      0.80      0.79       674\nweighted avg       0.81      0.79      0.80       674\n\n('T:', '7.067915201187134')\n('Epoch num - ', 0, ' and batch num ', 132)\n(0.40641242265701294,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.83      0.86       382\n           1       0.79      0.86      0.83       292\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.84      0.84      0.84       674\nweighted avg       0.85      0.84      0.84       674\n\n('T:', '7.018363952636719')\n('Epoch num - ', 0, ' and batch num ', 133)\n(0.40590164065361023,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.77      0.83       414\n           1       0.70      0.87      0.77       260\n\n   micro avg       0.80      0.80      0.80       674\n   macro avg       0.80      0.82      0.80       674\nweighted avg       0.82      0.80      0.81       674\n\n('T:', '6.766697645187378')\n('Epoch num - ', 0, ' and batch num ', 134)\n(0.41910383105278015,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.77      0.83       414\n           1       0.70      0.86      0.77       260\n\n   micro avg       0.81      0.81      0.81       674\n   macro avg       0.80      0.82      0.80       674\nweighted avg       0.82      0.81      0.81       674\n\n('T:', '6.803644180297852')\n('Epoch num - ', 0, ' and batch num ', 135)\n(0.4256861209869385,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.81      0.86       392\n           1       0.77      0.89      0.83       282\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.84      0.85      0.84       674\nweighted avg       0.85      0.84      0.85       674\n\n('T:', '6.792189836502075')\n('Epoch num - ', 0, ' and batch num ', 136)\n(0.3777364492416382,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.93      0.80      0.86       422\n           1       0.73      0.90      0.81       252\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.85      0.83       674\nweighted avg       0.86      0.84      0.84       674\n\n('T:', '6.657965183258057')\n('Epoch num - ', 0, ' and batch num ', 137)\n(0.3722290098667145,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.75      0.83       444\n           1       0.65      0.88      0.75       230\n\n   micro avg       0.80      0.80      0.80       674\n   macro avg       0.79      0.82      0.79       674\nweighted avg       0.83      0.80      0.80       674\n\n('T:', '6.811648845672607')\n('Epoch num - ', 0, ' and batch num ', 138)\n(0.4396141469478607,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.75      0.83       422\n           1       0.68      0.88      0.77       252\n\n   micro avg       0.80      0.80      0.80       674\n   macro avg       0.80      0.82      0.80       674\nweighted avg       0.83      0.80      0.80       674\n\n('T:', '6.763807773590088')\n('Epoch num - ', 0, ' and batch num ', 139)\n(0.41696715354919434,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.76      0.83       419\n           1       0.69      0.88      0.77       255\n\n   micro avg       0.80      0.80      0.80       674\n   macro avg       0.80      0.82      0.80       674\nweighted avg       0.83      0.80      0.81       674\n\n('T:', '7.019283771514893')\n('Epoch num - ', 0, ' and batch num ', 140)\n(0.4207831919193268,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.78      0.84       625\n           1       0.71      0.87      0.78       392\n\n   micro avg       0.81      0.81      0.81      1017\n   macro avg       0.81      0.82      0.81      1017\nweighted avg       0.83      0.81      0.82      1017\n\n('T:', '4.031271696090698')\n(0.39908185601234436,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.75      0.83       434\n           1       0.67      0.89      0.76       240\n\n   micro avg       0.80      0.80      0.80       674\n   macro avg       0.79      0.82      0.80       674\nweighted avg       0.83      0.80      0.81       674\n\n('T:', '6.5082385540008545')\n('Epoch num - ', 0, ' and batch num ', 141)\n(0.4131256937980652,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.78      0.84       410\n           1       0.72      0.86      0.78       264\n\n   micro avg       0.81      0.81      0.81       674\n   macro avg       0.81      0.82      0.81       674\nweighted avg       0.83      0.81      0.82       674\n\n('T:', '6.776871919631958')\n('Epoch num - ', 0, ' and batch num ', 142)\n(0.4208142161369324,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.75      0.81       391\n           1       0.71      0.86      0.78       283\n\n   micro avg       0.79      0.79      0.79       674\n   macro avg       0.79      0.80      0.79       674\nweighted avg       0.81      0.79      0.79       674\n\n('T:', '6.892090320587158')\n('Epoch num - ', 0, ' and batch num ', 143)\n(0.4502468407154083,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.76      0.83       419\n           1       0.69      0.86      0.77       255\n\n   micro avg       0.80      0.80      0.80       674\n   macro avg       0.79      0.81      0.80       674\nweighted avg       0.82      0.80      0.80       674\n\n('T:', '6.736949920654297')\n('Epoch num - ', 0, ' and batch num ', 144)\n(0.43879464268684387,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.80      0.84       403\n           1       0.74      0.86      0.80       271\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.82      0.83      0.82       674\nweighted avg       0.83      0.82      0.82       674\n\n('T:', '7.087730407714844')\n('Epoch num - ', 0, ' and batch num ', 145)\n(0.40831583738327026,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.76      0.82       398\n           1       0.72      0.86      0.78       276\n\n   micro avg       0.80      0.80      0.80       674\n   macro avg       0.80      0.81      0.80       674\nweighted avg       0.82      0.80      0.81       674\n\n('T:', '6.795300006866455')\n('Epoch num - ', 0, ' and batch num ', 146)\n(0.42920804023742676,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.74      0.81       419\n           1       0.67      0.86      0.75       255\n\n   micro avg       0.79      0.79      0.79       674\n   macro avg       0.78      0.80      0.78       674\nweighted avg       0.81      0.79      0.79       674\n\n('T:', '6.595584392547607')\n('Epoch num - ', 0, ' and batch num ', 147)\n(0.44440698623657227,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.89      0.75      0.81       408\n           1       0.69      0.86      0.77       266\n\n   micro avg       0.79      0.79      0.79       674\n   macro avg       0.79      0.81      0.79       674\nweighted avg       0.81      0.79      0.80       674\n\n('T:', '6.894518136978149')\n('Epoch num - ', 0, ' and batch num ', 148)\n(0.4250272810459137,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.76      0.81       387\n           1       0.72      0.84      0.78       287\n\n   micro avg       0.79      0.79      0.79       674\n   macro avg       0.79      0.80      0.79       674\nweighted avg       0.80      0.79      0.79       674\n\n('T:', '6.946535348892212')\n('Epoch num - ', 0, ' and batch num ', 149)\n(0.43637293577194214,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.78      0.84       407\n           1       0.72      0.88      0.79       267\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.81      0.83      0.81       674\nweighted avg       0.83      0.82      0.82       674\n\n('T:', '6.521574020385742')\n('Epoch num - ', 0, ' and batch num ', 150)\n(0.4133205711841583,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.78      0.84       625\n           1       0.71      0.89      0.79       392\n\n   micro avg       0.82      0.82      0.82      1017\n   macro avg       0.81      0.83      0.82      1017\nweighted avg       0.84      0.82      0.82      1017\n\n('T:', '4.103943347930908')\n(0.4022429287433624,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.75      0.82       419\n           1       0.68      0.87      0.76       255\n\n   micro avg       0.80      0.80      0.80       674\n   macro avg       0.79      0.81      0.79       674\nweighted avg       0.82      0.80      0.80       674\n\n('T:', '6.683712959289551')\n('Epoch num - ', 0, ' and batch num ', 151)\n(0.44528841972351074,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.75      0.83       429\n           1       0.67      0.89      0.76       245\n\n   micro avg       0.80      0.80      0.80       674\n   macro avg       0.80      0.82      0.79       674\nweighted avg       0.83      0.80      0.80       674\n\n('T:', '7.075613260269165')\n('Epoch num - ', 0, ' and batch num ', 152)\n(0.4191092252731323,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.78      0.83       411\n           1       0.71      0.86      0.78       263\n\n   micro avg       0.81      0.81      0.81       674\n   macro avg       0.80      0.82      0.80       674\nweighted avg       0.82      0.81      0.81       674\n\n('T:', '6.924258470535278')\n('Epoch num - ', 0, ' and batch num ', 153)\n(0.4228624701499939,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.76      0.82       406\n           1       0.71      0.87      0.78       268\n\n   micro avg       0.80      0.80      0.80       674\n   macro avg       0.80      0.81      0.80       674\nweighted avg       0.82      0.80      0.81       674\n\n('T:', '6.744432687759399')\n('Epoch num - ', 0, ' and batch num ', 154)\n(0.4359414279460907,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.78      0.84       408\n           1       0.73      0.88      0.80       266\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.82      0.83      0.82       674\nweighted avg       0.84      0.82      0.82       674\n\n('T:', '6.923192501068115')\n('Epoch num - ', 0, ' and batch num ', 155)\n(0.40709859132766724,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.77      0.83       397\n           1       0.73      0.88      0.80       277\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.82      0.83      0.81       674\nweighted avg       0.83      0.82      0.82       674\n\n('T:', '7.301657676696777')\n('Epoch num - ', 0, ' and batch num ', 156)\n(0.3977726399898529,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.77      0.82       392\n           1       0.72      0.85      0.78       282\n\n   micro avg       0.80      0.80      0.80       674\n   macro avg       0.80      0.81      0.80       674\nweighted avg       0.81      0.80      0.80       674\n\n('T:', '7.031588554382324')\n('Epoch num - ', 0, ' and batch num ', 157)\n(0.4342539608478546,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.78      0.83       399\n           1       0.73      0.86      0.79       275\n\n   micro avg       0.81      0.81      0.81       674\n   macro avg       0.81      0.82      0.81       674\nweighted avg       0.83      0.81      0.81       674\n\n('T:', '6.720791578292847')\n('Epoch num - ', 0, ' and batch num ', 158)\n(0.4095068573951721,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.78      0.84       410\n           1       0.72      0.89      0.80       264\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.82      0.83      0.82       674\nweighted avg       0.84      0.82      0.82       674\n\n('T:', '6.853091478347778')\n('Epoch num - ', 0, ' and batch num ', 159)\n(0.39776691794395447,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.76      0.83       413\n           1       0.70      0.87      0.77       261\n\n   micro avg       0.80      0.80      0.80       674\n   macro avg       0.80      0.82      0.80       674\nweighted avg       0.82      0.80      0.81       674\n\n('T:', '6.79172945022583')\n('Epoch num - ', 0, ' and batch num ', 160)\n(0.4263541102409363,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.79      0.84       625\n           1       0.72      0.88      0.79       392\n\n   micro avg       0.82      0.82      0.82      1017\n   macro avg       0.82      0.83      0.82      1017\nweighted avg       0.84      0.82      0.82      1017\n\n('T:', '4.088826656341553')\n(0.39596566557884216,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.80      0.85       418\n           1       0.73      0.88      0.80       256\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.82      0.84      0.82       674\nweighted avg       0.84      0.83      0.83       674\n\n('T:', '6.478675603866577')\n('Epoch num - ', 0, ' and batch num ', 161)\n(0.4162648320198059,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.80      0.85       386\n           1       0.77      0.88      0.82       288\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.84      0.83       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.952544212341309')\n('Epoch num - ', 0, ' and batch num ', 162)\n(0.410507470369339,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.78      0.83       410\n           1       0.71      0.85      0.77       264\n\n   micro avg       0.81      0.81      0.81       674\n   macro avg       0.80      0.81      0.80       674\nweighted avg       0.82      0.81      0.81       674\n\n('T:', '6.755455255508423')\n('Epoch num - ', 0, ' and batch num ', 163)\n(0.4373147189617157,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.89      0.82      0.85       397\n           1       0.77      0.86      0.81       277\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.83      0.84      0.83       674\nweighted avg       0.84      0.83      0.83       674\n\n('T:', '6.8274312019348145')\n('Epoch num - ', 0, ' and batch num ', 164)\n(0.38621950149536133,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.79      0.84       401\n           1       0.74      0.89      0.81       273\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.83      0.84      0.83       674\nweighted avg       0.84      0.83      0.83       674\n\n('T:', '6.888763666152954')\n('Epoch num - ', 0, ' and batch num ', 165)\n(0.39377012848854065,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.80      0.86       410\n           1       0.74      0.88      0.81       264\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.84      0.83       674\nweighted avg       0.85      0.84      0.84       674\n\n('T:', '6.724951982498169')\n('Epoch num - ', 0, ' and batch num ', 166)\n(0.3836553692817688,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.80      0.85       405\n           1       0.75      0.89      0.81       269\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.85      0.83       674\nweighted avg       0.85      0.84      0.84       674\n\n('T:', '6.939180135726929')\n('Epoch num - ', 0, ' and batch num ', 167)\n(0.37685704231262207,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.78      0.85       433\n           1       0.69      0.88      0.78       241\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.81      0.83      0.81       674\nweighted avg       0.84      0.82      0.82       674\n\n('T:', '6.744138717651367')\n('Epoch num - ', 0, ' and batch num ', 168)\n(0.41330626606941223,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.82      0.86       402\n           1       0.77      0.88      0.82       272\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.84      0.85      0.84       674\nweighted avg       0.85      0.84      0.84       674\n\n('T:', '6.607565879821777')\n('Epoch num - ', 0, ' and batch num ', 169)\n(0.3734268844127655,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.80      0.86       414\n           1       0.74      0.90      0.81       260\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.85      0.83       674\nweighted avg       0.85      0.84      0.84       674\n\n('T:', '6.615235805511475')\n('Epoch num - ', 0, ' and batch num ', 170)\n(0.3886765241622925,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.80      0.85       625\n           1       0.73      0.87      0.79       392\n\n   micro avg       0.83      0.83      0.83      1017\n   macro avg       0.82      0.83      0.82      1017\nweighted avg       0.84      0.83      0.83      1017\n\n('T:', '4.079734802246094')\n(0.37448936700820923,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.83      0.87       401\n           1       0.78      0.89      0.83       273\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.6808600425720215')\n('Epoch num - ', 0, ' and batch num ', 171)\n(0.3699605166912079,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.81      0.85       401\n           1       0.75      0.84      0.79       273\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.82      0.83      0.82       674\nweighted avg       0.83      0.82      0.82       674\n\n('T:', '6.667876720428467')\n('Epoch num - ', 0, ' and batch num ', 172)\n(0.3888480067253113,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.93      0.82      0.87       411\n           1       0.77      0.90      0.83       263\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.86      0.85       674\nweighted avg       0.87      0.85      0.86       674\n\n('T:', '6.885402202606201')\n('Epoch num - ', 0, ' and batch num ', 173)\n(0.37263208627700806,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.85      0.86       371\n           1       0.82      0.85      0.84       303\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.8063719272613525')\n('Epoch num - ', 0, ' and batch num ', 174)\n(0.36120370030403137,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.80      0.84       408\n           1       0.73      0.83      0.78       266\n\n   micro avg       0.81      0.81      0.81       674\n   macro avg       0.81      0.82      0.81       674\nweighted avg       0.82      0.81      0.82       674\n\n('T:', '6.94065260887146')\n('Epoch num - ', 0, ' and batch num ', 175)\n(0.3976486623287201,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.82      0.86       409\n           1       0.75      0.86      0.80       265\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.83      0.84      0.83       674\nweighted avg       0.84      0.83      0.84       674\n\n('T:', '7.266218423843384')\n('Epoch num - ', 0, ' and batch num ', 176)\n(0.3834555447101593,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.85      0.87       404\n           1       0.78      0.84      0.81       270\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.84      0.84      0.84       674\nweighted avg       0.85      0.84      0.84       674\n\n('T:', '7.410197019577026')\n('Epoch num - ', 0, ' and batch num ', 177)\n(0.37467849254608154,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.86      0.87       404\n           1       0.80      0.85      0.82       270\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.86      0.85      0.85       674\n\n('T:', '6.915148973464966')\n('Epoch num - ', 0, ' and batch num ', 178)\n(0.3630479872226715,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.86      0.87       388\n           1       0.81      0.84      0.83       286\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.936059236526489')\n('Epoch num - ', 0, ' and batch num ', 179)\n(0.3742827773094177,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.83      0.86       419\n           1       0.75      0.83      0.79       255\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.82      0.83      0.83       674\nweighted avg       0.84      0.83      0.83       674\n\n('T:', '6.646074295043945')\n('Epoch num - ', 0, ' and batch num ', 180)\n(0.3917195200920105,)\n('TEST COST',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.90      0.84      0.87       625\n           1       0.76      0.85      0.80       392\n\n   micro avg       0.84      0.84      0.84      1017\n   macro avg       0.83      0.84      0.83      1017\nweighted avg       0.85      0.84      0.84      1017\n\n('T:', '4.03213906288147')\n(0.36608168482780457,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.84      0.88       413\n           1       0.78      0.88      0.83       261\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.747009754180908')\n('Epoch num - ', 0, ' and batch num ', 181)\n(0.3505975008010864,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.87      0.87       391\n           1       0.82      0.82      0.82       283\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.968927383422852')\n('Epoch num - ', 0, ' and batch num ', 182)\n(0.36712029576301575,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.85      0.85       382\n           1       0.80      0.80      0.80       292\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.82      0.82      0.82       674\nweighted avg       0.83      0.83      0.83       674\n\n('T:', '7.09963059425354')\n('Epoch num - ', 0, ' and batch num ', 183)\n(0.3879941403865814,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.85      0.87       405\n           1       0.79      0.85      0.82       269\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.85      0.85       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.912482023239136')\n('Epoch num - ', 0, ' and batch num ', 184)\n(0.38229599595069885,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.81      0.84       402\n           1       0.75      0.83      0.79       272\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.82      0.82      0.82       674\nweighted avg       0.83      0.82      0.82       674\n\n('T:', '6.789567470550537')\n('Epoch num - ', 0, ' and batch num ', 185)\n(0.3914254307746887,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.88      0.90       411\n           1       0.82      0.87      0.84       263\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.691524505615234')\n('Epoch num - ', 0, ' and batch num ', 186)\n(0.33522215485572815,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.85      0.88       431\n           1       0.76      0.86      0.81       243\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.85      0.84       674\nweighted avg       0.86      0.85      0.85       674\n\n('T:', '6.755778551101685')\n('Epoch num - ', 0, ' and batch num ', 187)\n(0.36575746536254883,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.86      0.87       419\n           1       0.78      0.83      0.80       255\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.84      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.864954471588135')\n('Epoch num - ', 0, ' and batch num ', 188)\n(0.35228437185287476,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.85      0.86       402\n           1       0.79      0.81      0.80       272\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.83      0.83      0.83       674\nweighted avg       0.83      0.83      0.83       674\n\n('T:', '6.992746829986572')\n('Epoch num - ', 0, ' and batch num ', 189)\n(0.3869876265525818,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.81      0.87      0.84       378\n           1       0.82      0.75      0.78       296\n\n   micro avg       0.81      0.81      0.81       674\n   macro avg       0.81      0.81      0.81       674\nweighted avg       0.81      0.81      0.81       674\n\n('T:', '6.88785195350647')\n('Epoch num - ', 0, ' and batch num ', 190)\n(0.41170036792755127,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.85      0.86       625\n           1       0.77      0.79      0.78       392\n\n   micro avg       0.83      0.83      0.83      1017\n   macro avg       0.82      0.82      0.82      1017\nweighted avg       0.83      0.83      0.83      1017\n\n('T:', '4.060413599014282')\n(0.3769551217556,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.86      0.86       402\n           1       0.79      0.81      0.80       272\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.83      0.83       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.7579920291900635')\n('Epoch num - ', 0, ' and batch num ', 191)\n(0.39265039563179016,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.83      0.85       415\n           1       0.74      0.80      0.77       259\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.81      0.81      0.81       674\nweighted avg       0.82      0.82      0.82       674\n\n('T:', '6.821497440338135')\n('Epoch num - ', 0, ' and batch num ', 192)\n(0.3960399329662323,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.87      0.87       411\n           1       0.80      0.80      0.80       263\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.84      0.84      0.84       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.710942268371582')\n('Epoch num - ', 0, ' and batch num ', 193)\n(0.3701804578304291,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.87      0.88       422\n           1       0.79      0.83      0.81       252\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.85      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.613360404968262')\n('Epoch num - ', 0, ' and batch num ', 194)\n(0.3542730212211609,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.85      0.87       426\n           1       0.75      0.81      0.78       248\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.82      0.83      0.82       674\nweighted avg       0.84      0.83      0.84       674\n\n('T:', '6.947234869003296')\n('Epoch num - ', 0, ' and batch num ', 195)\n(0.37193769216537476,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.86      0.87       416\n           1       0.78      0.81      0.80       258\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.84      0.83       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.615109920501709')\n('Epoch num - ', 0, ' and batch num ', 196)\n(0.3439162075519562,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.87      0.85      0.86       421\n           1       0.76      0.78      0.77       253\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.81      0.82      0.81       674\nweighted avg       0.83      0.82      0.83       674\n\n('T:', '6.7334864139556885')\n('Epoch num - ', 0, ' and batch num ', 197)\n(0.3929588794708252,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.89      0.88       397\n           1       0.84      0.79      0.81       277\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.84      0.85       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.636523485183716')\n('Epoch num - ', 0, ' and batch num ', 198)\n(0.3593098819255829,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.90      0.87       398\n           1       0.83      0.75      0.79       276\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.84      0.82      0.83       674\nweighted avg       0.84      0.84      0.83       674\n\n('T:', '6.699464321136475')\n('Epoch num - ', 0, ' and batch num ', 199)\n(0.36522096395492554,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.89      0.87       398\n           1       0.82      0.76      0.79       276\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.83      0.83       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '7.214440822601318')\n('Epoch num - ', 0, ' and batch num ', 200)\n(0.3765130639076233,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.87      0.87       625\n           1       0.79      0.78      0.79       392\n\n   micro avg       0.84      0.84      0.84      1017\n   macro avg       0.83      0.83      0.83      1017\nweighted avg       0.84      0.84      0.84      1017\n\n('T:', '4.115325689315796')\n(0.3788077235221863,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.88      0.88       423\n           1       0.80      0.80      0.80       251\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.84      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.728126287460327')\n('Epoch num - ', 0, ' and batch num ', 201)\n(0.3415142595767975,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.87      0.86       409\n           1       0.80      0.76      0.78       265\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.82      0.82      0.82       674\nweighted avg       0.83      0.83      0.83       674\n\n('T:', '6.796971082687378')\n('Epoch num - ', 0, ' and batch num ', 202)\n(0.41718417406082153,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.81      0.89      0.85       390\n           1       0.82      0.72      0.77       284\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.82      0.80      0.81       674\nweighted avg       0.82      0.82      0.82       674\n\n('T:', '7.150996208190918')\n('Epoch num - ', 0, ' and batch num ', 203)\n(0.4000433087348938,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.88      0.88       414\n           1       0.80      0.80      0.80       260\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.84      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.476425647735596')\n('Epoch num - ', 0, ' and batch num ', 204)\n(0.359744131565094,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.91      0.88       403\n           1       0.85      0.77      0.80       271\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.84      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.9299962520599365')\n('Epoch num - ', 0, ' and batch num ', 205)\n(0.3545384407043457,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.82      0.87      0.84       407\n           1       0.78      0.70      0.74       267\n\n   micro avg       0.81      0.81      0.81       674\n   macro avg       0.80      0.79      0.79       674\nweighted avg       0.80      0.81      0.80       674\n\n('T:', '6.77790904045105')\n('Epoch num - ', 0, ' and batch num ', 206)\n(0.3910132646560669,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.89      0.87       413\n           1       0.81      0.75      0.78       261\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.83      0.82      0.82       674\nweighted avg       0.83      0.83      0.83       674\n\n('T:', '6.5075812339782715')\n('Epoch num - ', 0, ' and batch num ', 207)\n(0.39397650957107544,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.91      0.87       393\n           1       0.85      0.77      0.81       281\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.84      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.819352388381958')\n('Epoch num - ', 0, ' and batch num ', 208)\n(0.3465096056461334,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.83      0.88      0.86       396\n           1       0.82      0.75      0.78       278\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.83      0.82      0.82       674\nweighted avg       0.83      0.83      0.83       674\n\n('T:', '6.677058696746826')\n('Epoch num - ', 0, ' and batch num ', 209)\n(0.3866671919822693,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.83      0.89      0.86       409\n           1       0.81      0.72      0.76       265\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.82      0.81      0.81       674\nweighted avg       0.82      0.82      0.82       674\n\n('T:', '6.840492486953735')\n('Epoch num - ', 0, ' and batch num ', 210)\n(0.4091041684150696,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.87      0.86       625\n           1       0.79      0.76      0.77       392\n\n   micro avg       0.83      0.83      0.83      1017\n   macro avg       0.82      0.81      0.82      1017\nweighted avg       0.83      0.83      0.83      1017\n\n('T:', '4.081592321395874')\n(0.3897390067577362,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.89      0.86       404\n           1       0.82      0.74      0.78       270\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.83      0.82      0.82       674\nweighted avg       0.83      0.83      0.83       674\n\n('T:', '6.833515882492065')\n('Epoch num - ', 0, ' and batch num ', 211)\n(0.3794326186180115,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.83      0.88      0.85       399\n           1       0.81      0.74      0.77       275\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.82      0.81      0.81       674\nweighted avg       0.82      0.82      0.82       674\n\n('T:', '6.9249396324157715')\n('Epoch num - ', 0, ' and batch num ', 212)\n(0.41429010033607483,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.85      0.92      0.88       400\n           1       0.87      0.76      0.81       274\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.84      0.85       674\nweighted avg       0.86      0.86      0.85       674\n\n('T:', '6.752737045288086')\n('Epoch num - ', 0, ' and batch num ', 213)\n(0.34523317217826843,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.83      0.87      0.85       395\n           1       0.80      0.74      0.77       279\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.81      0.81      0.81       674\nweighted avg       0.82      0.82      0.82       674\n\n('T:', '6.9214701652526855')\n('Epoch num - ', 0, ' and batch num ', 214)\n(0.40495625138282776,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.89      0.87       412\n           1       0.81      0.74      0.78       262\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.83      0.82      0.82       674\nweighted avg       0.83      0.83      0.83       674\n\n('T:', '6.6232826709747314')\n('Epoch num - ', 0, ' and batch num ', 215)\n(0.3748781681060791,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.91      0.87       398\n           1       0.86      0.74      0.80       276\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.85      0.83      0.84       674\nweighted avg       0.85      0.84      0.84       674\n\n('T:', '6.654343366622925')\n('Epoch num - ', 0, ' and batch num ', 216)\n(0.3724583387374878,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.89      0.87       413\n           1       0.82      0.76      0.79       261\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.84      0.83      0.83       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.828745365142822')\n('Epoch num - ', 0, ' and batch num ', 217)\n(0.39333009719848633,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.92      0.88       397\n           1       0.86      0.75      0.80       277\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.83      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.89757513999939')\n('Epoch num - ', 0, ' and batch num ', 218)\n(0.3587145209312439,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.90      0.87       414\n           1       0.82      0.73      0.77       260\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.83      0.81      0.82       674\nweighted avg       0.83      0.83      0.83       674\n\n('T:', '6.769431114196777')\n('Epoch num - ', 0, ' and batch num ', 219)\n(0.38358694314956665,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.89      0.87       412\n           1       0.82      0.76      0.79       262\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.84      0.82      0.83       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.906018257141113')\n('Epoch num - ', 0, ' and batch num ', 220)\n(0.3703613877296448,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.88      0.87       625\n           1       0.81      0.76      0.78       392\n\n   micro avg       0.84      0.84      0.84      1017\n   macro avg       0.83      0.82      0.83      1017\nweighted avg       0.84      0.84      0.84      1017\n\n('T:', '4.145395278930664')\n(0.39009660482406616,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.83      0.89      0.86       403\n           1       0.82      0.72      0.76       271\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.82      0.81      0.81       674\nweighted avg       0.82      0.82      0.82       674\n\n('T:', '6.929611921310425')\n('Epoch num - ', 0, ' and batch num ', 221)\n(0.40108221769332886,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.90      0.87       412\n           1       0.82      0.73      0.77       262\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.83      0.81      0.82       674\nweighted avg       0.83      0.83      0.83       674\n\n('T:', '6.692453861236572')\n('Epoch num - ', 0, ' and batch num ', 222)\n(0.37107428908348083,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.92      0.88       406\n           1       0.85      0.74      0.79       268\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.83      0.83       674\nweighted avg       0.85      0.85      0.84       674\n\n('T:', '7.284619092941284')\n('Epoch num - ', 0, ' and batch num ', 223)\n(0.35757118463516235,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.91      0.88       411\n           1       0.84      0.76      0.80       263\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.83      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.976252317428589')\n('Epoch num - ', 0, ' and batch num ', 224)\n(0.3449445366859436,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.90      0.87       389\n           1       0.85      0.77      0.81       285\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.85      0.83      0.84       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.90964150428772')\n('Epoch num - ', 0, ' and batch num ', 225)\n(0.37576133012771606,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.83      0.89      0.86       396\n           1       0.82      0.74      0.78       278\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.83      0.82      0.82       674\nweighted avg       0.83      0.83      0.83       674\n\n('T:', '6.730868816375732')\n('Epoch num - ', 0, ' and batch num ', 226)\n(0.4265053868293762,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.83      0.91      0.87       389\n           1       0.86      0.74      0.79       285\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.84      0.83      0.83       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.860218524932861')\n('Epoch num - ', 0, ' and batch num ', 227)\n(0.36744117736816406,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.90      0.87       400\n           1       0.83      0.76      0.79       274\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.84      0.83      0.83       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.679808616638184')\n('Epoch num - ', 0, ' and batch num ', 228)\n(0.36943575739860535,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.86      0.86       417\n           1       0.77      0.75      0.76       257\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.81      0.81      0.81       674\nweighted avg       0.82      0.82      0.82       674\n\n('T:', '6.793537139892578')\n('Epoch num - ', 0, ' and batch num ', 229)\n(0.41130197048187256,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.83      0.88      0.86       408\n           1       0.80      0.73      0.77       266\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.82      0.81      0.81       674\nweighted avg       0.82      0.82      0.82       674\n\n('T:', '6.798839807510376')\n('Epoch num - ', 0, ' and batch num ', 230)\n(0.426872581243515,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.88      0.87       625\n           1       0.80      0.78      0.79       392\n\n   micro avg       0.84      0.84      0.84      1017\n   macro avg       0.83      0.83      0.83      1017\nweighted avg       0.84      0.84      0.84      1017\n\n('T:', '4.096958637237549')\n(0.3782593011856079,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.90      0.87       400\n           1       0.83      0.76      0.79       274\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.84      0.83      0.83       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.787188529968262')\n('Epoch num - ', 0, ' and batch num ', 231)\n(0.3678624629974365,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.90      0.88       408\n           1       0.84      0.79      0.81       266\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.939183712005615')\n('Epoch num - ', 0, ' and batch num ', 232)\n(0.3882005214691162,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.91      0.89       413\n           1       0.85      0.77      0.80       261\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.84      0.85       674\nweighted avg       0.86      0.86      0.85       674\n\n('T:', '6.825230121612549')\n('Epoch num - ', 0, ' and batch num ', 233)\n(0.33407893776893616,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.89      0.88       424\n           1       0.81      0.77      0.79       250\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.83      0.83       674\nweighted avg       0.84      0.85      0.84       674\n\n('T:', '6.752108573913574')\n('Epoch num - ', 0, ' and batch num ', 234)\n(0.3313784599304199,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.90      0.87       385\n           1       0.86      0.77      0.81       289\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.84      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.700957298278809')\n('Epoch num - ', 0, ' and batch num ', 235)\n(0.3863048255443573,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.92      0.90       395\n           1       0.88      0.81      0.85       279\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.88      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '7.298672676086426')\n('Epoch num - ', 0, ' and batch num ', 236)\n(0.31600692868232727,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.90      0.88       394\n           1       0.85      0.78      0.81       280\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.84      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.724746465682983')\n('Epoch num - ', 0, ' and batch num ', 237)\n(0.34450551867485046,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.89      0.89       431\n           1       0.80      0.83      0.82       243\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.85      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.591102838516235')\n('Epoch num - ', 0, ' and batch num ', 238)\n(0.31962689757347107,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.91      0.89       394\n           1       0.86      0.82      0.84       280\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.86      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.818181037902832')\n('Epoch num - ', 0, ' and batch num ', 239)\n(0.30199694633483887,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.88      0.88       406\n           1       0.82      0.82      0.82       268\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.644697904586792')\n('Epoch num - ', 0, ' and batch num ', 240)\n(0.3290362060070038,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.88      0.88       625\n           1       0.80      0.80      0.80       392\n\n   micro avg       0.85      0.85      0.85      1017\n   macro avg       0.84      0.84      0.84      1017\nweighted avg       0.85      0.85      0.85      1017\n\n('T:', '4.0448317527771')\n(0.36205023527145386,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.91      0.89       400\n           1       0.86      0.80      0.83       274\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.85      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.575090169906616')\n('Epoch num - ', 0, ' and batch num ', 241)\n(0.35248222947120667,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.87      0.88       418\n           1       0.79      0.82      0.80       256\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.84      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.933008193969727')\n('Epoch num - ', 0, ' and batch num ', 242)\n(0.34870895743370056,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.89      0.88       410\n           1       0.82      0.80      0.81       264\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.84      0.85       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.852252244949341')\n('Epoch num - ', 0, ' and batch num ', 243)\n(0.3622659146785736,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.89      0.89       410\n           1       0.83      0.83      0.83       264\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.754698038101196')\n('Epoch num - ', 0, ' and batch num ', 244)\n(0.3270132541656494,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.91      0.88       377\n           1       0.88      0.79      0.83       297\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.85      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.9357898235321045')\n('Epoch num - ', 0, ' and batch num ', 245)\n(0.3690253496170044,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.90      0.87      0.88       413\n           1       0.80      0.84      0.82       261\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.703538417816162')\n('Epoch num - ', 0, ' and batch num ', 246)\n(0.369585782289505,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.87      0.88       409\n           1       0.81      0.84      0.82       265\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.8790295124053955')\n('Epoch num - ', 0, ' and batch num ', 247)\n(0.34877339005470276,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.89      0.87       380\n           1       0.85      0.80      0.82       294\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.84      0.85       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '7.017469167709351')\n('Epoch num - ', 0, ' and batch num ', 248)\n(0.36727508902549744,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.87      0.90       440\n           1       0.78      0.86      0.82       234\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.85      0.87      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.826959609985352')\n('Epoch num - ', 0, ' and batch num ', 249)\n(0.31465861201286316,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.93      0.89      0.91       423\n           1       0.82      0.88      0.85       251\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.88      0.88       674\nweighted avg       0.89      0.88      0.89       674\n\n('T:', '6.906477689743042')\n('Epoch num - ', 0, ' and batch num ', 250)\n(0.3152839243412018,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.87      0.88       625\n           1       0.80      0.84      0.82       392\n\n   micro avg       0.86      0.86      0.86      1017\n   macro avg       0.85      0.86      0.85      1017\nweighted avg       0.86      0.86      0.86      1017\n\n('T:', '4.068179607391357')\n(0.35125085711479187,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.86      0.89       424\n           1       0.78      0.88      0.83       250\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.87      0.86       674\nweighted avg       0.87      0.86      0.86       674\n\n('T:', '6.835861682891846')\n('Epoch num - ', 0, ' and batch num ', 251)\n(0.3167715072631836,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.87      0.86       399\n           1       0.81      0.78      0.79       275\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.83      0.83       674\nweighted avg       0.83      0.84      0.83       674\n\n('T:', '7.3123884201049805')\n('Epoch num - ', 0, ' and batch num ', 252)\n(0.3855741024017334,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.87      0.87       402\n           1       0.81      0.82      0.82       272\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.85      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.591012716293335')\n('Epoch num - ', 0, ' and batch num ', 253)\n(0.36341673135757446,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.90      0.89       392\n           1       0.85      0.84      0.84       282\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.750731706619263')\n('Epoch num - ', 0, ' and batch num ', 254)\n(0.30298665165901184,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.85      0.87       409\n           1       0.78      0.83      0.80       265\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.84      0.83       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '7.033214569091797')\n('Epoch num - ', 0, ' and batch num ', 255)\n(0.37124255299568176,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.86      0.88       419\n           1       0.78      0.85      0.82       255\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.85      0.85       674\nweighted avg       0.86      0.85      0.86       674\n\n('T:', '6.745855331420898')\n('Epoch num - ', 0, ' and batch num ', 256)\n(0.3327151834964752,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.88      0.89       408\n           1       0.82      0.83      0.83       266\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.6666224002838135')\n('Epoch num - ', 0, ' and batch num ', 257)\n(0.34981513023376465,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.87      0.88       396\n           1       0.83      0.86      0.84       278\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.9842143058776855')\n('Epoch num - ', 0, ' and batch num ', 258)\n(0.33749380707740784,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.84      0.87       406\n           1       0.78      0.84      0.81       268\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.84      0.84       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.750983476638794')\n('Epoch num - ', 0, ' and batch num ', 259)\n(0.35902172327041626,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.86      0.88       410\n           1       0.80      0.84      0.82       264\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.86      0.85      0.86       674\n\n('T:', '6.799982309341431')\n('Epoch num - ', 0, ' and batch num ', 260)\n(0.36046746373176575,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.86      0.89       625\n           1       0.79      0.88      0.83       392\n\n   micro avg       0.86      0.86      0.86      1017\n   macro avg       0.86      0.87      0.86      1017\nweighted avg       0.87      0.86      0.87      1017\n\n('T:', '4.0866310596466064')\n(0.3343455493450165,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.93      0.89      0.91       395\n           1       0.85      0.90      0.87       279\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.89      0.89      0.89       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '7.057052850723267')\n('Epoch num - ', 0, ' and batch num ', 261)\n(0.2793424427509308,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.92      0.88      0.90       405\n           1       0.83      0.88      0.85       269\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.88      0.88       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '7.075596570968628')\n('Epoch num - ', 0, ' and batch num ', 262)\n(0.32741501927375793,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.85      0.87       392\n           1       0.80      0.84      0.82       282\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.85      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.686232328414917')\n('Epoch num - ', 0, ' and batch num ', 263)\n(0.3977550268173218,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.88      0.89       397\n           1       0.83      0.85      0.84       277\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.87      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.898258447647095')\n('Epoch num - ', 0, ' and batch num ', 264)\n(0.33221080899238586,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.94      0.84      0.88       431\n           1       0.76      0.90      0.82       243\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.87      0.85       674\nweighted avg       0.87      0.86      0.86       674\n\n('T:', '6.63558554649353')\n('Epoch num - ', 0, ' and batch num ', 265)\n(0.3196360766887665,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.87      0.88       391\n           1       0.83      0.85      0.84       283\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.89729905128479')\n('Epoch num - ', 0, ' and batch num ', 266)\n(0.3259885311126709,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.94      0.88      0.91       432\n           1       0.80      0.90      0.85       242\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.89      0.88       674\nweighted avg       0.89      0.88      0.89       674\n\n('T:', '6.822412967681885')\n('Epoch num - ', 0, ' and batch num ', 267)\n(0.28823235630989075,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.86      0.89       385\n           1       0.83      0.89      0.86       289\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '7.145064115524292')\n('Epoch num - ', 0, ' and batch num ', 268)\n(0.3091866075992584,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.85      0.87       386\n           1       0.81      0.86      0.84       288\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.714229106903076')\n('Epoch num - ', 0, ' and batch num ', 269)\n(0.34387123584747314,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.82      0.87       406\n           1       0.77      0.88      0.82       268\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.85      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.873388767242432')\n('Epoch num - ', 0, ' and batch num ', 270)\n(0.37474676966667175,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.83      0.88       625\n           1       0.77      0.89      0.82       392\n\n   micro avg       0.85      0.85      0.85      1017\n   macro avg       0.85      0.86      0.85      1017\nweighted avg       0.86      0.85      0.86      1017\n\n('T:', '4.292461156845093')\n(0.3335421681404114,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.84      0.87       409\n           1       0.78      0.88      0.83       265\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.86      0.85       674\nweighted avg       0.86      0.85      0.86       674\n\n('T:', '6.692320346832275')\n('Epoch num - ', 0, ' and batch num ', 271)\n(0.351765900850296,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.84      0.87       404\n           1       0.78      0.86      0.82       270\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.85      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.699315786361694')\n('Epoch num - ', 0, ' and batch num ', 272)\n(0.3859730064868927,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.85      0.88       401\n           1       0.80      0.87      0.83       273\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '7.009406805038452')\n('Epoch num - ', 0, ' and batch num ', 273)\n(0.36427485942840576,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.94      0.87      0.90       402\n           1       0.83      0.92      0.87       272\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.88      0.89      0.89       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.9147233963012695')\n('Epoch num - ', 0, ' and batch num ', 274)\n(0.29621410369873047,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.82      0.87       427\n           1       0.74      0.87      0.80       247\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.85      0.83       674\nweighted avg       0.85      0.84      0.84       674\n\n('T:', '6.627421855926514')\n('Epoch num - ', 0, ' and batch num ', 275)\n(0.3705543577671051,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.81      0.86       410\n           1       0.75      0.88      0.81       264\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.85      0.84       674\nweighted avg       0.85      0.84      0.84       674\n\n('T:', '6.770671129226685')\n('Epoch num - ', 0, ' and batch num ', 276)\n(0.35402044653892517,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.93      0.87      0.90       412\n           1       0.81      0.90      0.86       262\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.89      0.88       674\nweighted avg       0.89      0.88      0.88       674\n\n('T:', '6.623694181442261')\n('Epoch num - ', 0, ' and batch num ', 277)\n(0.3225557804107666,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.88      0.89       398\n           1       0.83      0.87      0.85       276\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.88      0.87      0.87       674\n\n('T:', '6.73599910736084')\n('Epoch num - ', 0, ' and batch num ', 278)\n(0.3231731057167053,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.91      0.80      0.85       417\n           1       0.73      0.87      0.79       257\n\n   micro avg       0.82      0.82      0.82       674\n   macro avg       0.82      0.83      0.82       674\nweighted avg       0.84      0.82      0.83       674\n\n('T:', '6.977371692657471')\n('Epoch num - ', 0, ' and batch num ', 279)\n(0.4024140238761902,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.95      0.87      0.91       423\n           1       0.80      0.92      0.86       251\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.88      0.89      0.88       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.869934320449829')\n('Epoch num - ', 0, ' and batch num ', 280)\n(0.3184530735015869,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.83      0.87       625\n           1       0.76      0.89      0.82       392\n\n   micro avg       0.85      0.85      0.85      1017\n   macro avg       0.84      0.86      0.85      1017\nweighted avg       0.86      0.85      0.85      1017\n\n('T:', '4.073564529418945')\n(0.3344248831272125,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.93      0.85      0.89       409\n           1       0.80      0.90      0.85       265\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.88      0.87       674\nweighted avg       0.88      0.87      0.87       674\n\n('T:', '6.791451454162598')\n('Epoch num - ', 0, ' and batch num ', 281)\n(0.3181130290031433,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.93      0.86      0.89       402\n           1       0.81      0.90      0.85       272\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.88      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.589954137802124')\n('Epoch num - ', 0, ' and batch num ', 282)\n(0.33258551359176636,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.85      0.87       401\n           1       0.79      0.87      0.83       273\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.86      0.85       674\nweighted avg       0.86      0.85      0.86       674\n\n('T:', '6.737009763717651')\n('Epoch num - ', 0, ' and batch num ', 283)\n(0.3607156574726105,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.83      0.87       418\n           1       0.76      0.88      0.81       256\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.85      0.84       674\nweighted avg       0.86      0.85      0.85       674\n\n('T:', '6.795708417892456')\n('Epoch num - ', 0, ' and batch num ', 284)\n(0.3463585376739502,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.83      0.87       409\n           1       0.77      0.89      0.82       265\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.86      0.85       674\nweighted avg       0.86      0.85      0.85       674\n\n('T:', '7.096092462539673')\n('Epoch num - ', 0, ' and batch num ', 285)\n(0.33055350184440613,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.85      0.88       415\n           1       0.78      0.88      0.83       259\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.86       674\nweighted avg       0.87      0.86      0.86       674\n\n('T:', '6.862361192703247')\n('Epoch num - ', 0, ' and batch num ', 286)\n(0.32790908217430115,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.85      0.87       400\n           1       0.80      0.85      0.82       274\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.900158405303955')\n('Epoch num - ', 0, ' and batch num ', 287)\n(0.3624644875526428,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.84      0.86       402\n           1       0.78      0.85      0.81       272\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.84      0.84      0.84       674\nweighted avg       0.85      0.84      0.84       674\n\n('T:', '6.889693021774292')\n('Epoch num - ', 0, ' and batch num ', 288)\n(0.34898287057876587,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.88      0.89       406\n           1       0.82      0.86      0.84       268\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.87      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.894884824752808')\n('Epoch num - ', 0, ' and batch num ', 289)\n(0.3197741210460663,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.85      0.88       402\n           1       0.80      0.87      0.83       272\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.98842191696167')\n('Epoch num - ', 0, ' and batch num ', 290)\n(0.3536587357521057,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.84      0.88       625\n           1       0.77      0.88      0.82       392\n\n   micro avg       0.85      0.85      0.85      1017\n   macro avg       0.84      0.86      0.85      1017\nweighted avg       0.86      0.85      0.85      1017\n\n('T:', '4.047852277755737')\n(0.33533135056495667,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.94      0.83      0.88       422\n           1       0.76      0.91      0.83       252\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.87      0.85       674\nweighted avg       0.87      0.86      0.86       674\n\n('T:', '6.914823055267334')\n('Epoch num - ', 0, ' and batch num ', 291)\n(0.3434792459011078,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.85      0.88       405\n           1       0.80      0.88      0.84       269\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.87      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.903144121170044')\n('Epoch num - ', 0, ' and batch num ', 292)\n(0.3199599087238312,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.85      0.88       410\n           1       0.79      0.86      0.82       264\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.7920897006988525')\n('Epoch num - ', 0, ' and batch num ', 293)\n(0.3350985646247864,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.87      0.87       382\n           1       0.83      0.83      0.83       292\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '7.5251336097717285')\n('Epoch num - ', 0, ' and batch num ', 294)\n(0.3572014570236206,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.92      0.84      0.88       426\n           1       0.76      0.88      0.82       248\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.86      0.85       674\nweighted avg       0.86      0.85      0.86       674\n\n('T:', '6.906008005142212')\n('Epoch num - ', 0, ' and batch num ', 295)\n(0.337178498506546,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.86      0.89       414\n           1       0.80      0.88      0.84       260\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.87      0.87       674\nweighted avg       0.88      0.87      0.87       674\n\n('T:', '6.694069147109985')\n('Epoch num - ', 0, ' and batch num ', 296)\n(0.32957661151885986,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.85      0.87       393\n           1       0.80      0.85      0.83       281\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '7.1478636264801025')\n('Epoch num - ', 0, ' and batch num ', 297)\n(0.3449406325817108,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.84      0.86       398\n           1       0.78      0.83      0.80       276\n\n   micro avg       0.83      0.83      0.83       674\n   macro avg       0.83      0.83      0.83       674\nweighted avg       0.84      0.83      0.83       674\n\n('T:', '6.714827537536621')\n('Epoch num - ', 0, ' and batch num ', 298)\n(0.38963624835014343,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.85      0.88       415\n           1       0.79      0.88      0.83       259\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.87      0.86       674\nweighted avg       0.87      0.86      0.86       674\n\n('T:', '6.796439170837402')\n('Epoch num - ', 0, ' and batch num ', 299)\n(0.3316231966018677,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([124])) that is different to the input size (torch.Size([124, 1])) is deprecated. Please ensure they have the same size.\n  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.87      0.90      0.88        68\n           1       0.87      0.84      0.85        56\n\n   micro avg       0.87      0.87      0.87       124\n   macro avg       0.87      0.87      0.87       124\nweighted avg       0.87      0.87      0.87       124\n\n('T:', '1.4411964416503906')\n('Epoch num - ', 0, ' and batch num ', 300)\n(0.3487355709075928,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.84      0.88       625\n           1       0.78      0.89      0.83       392\n\n   micro avg       0.86      0.86      0.86      1017\n   macro avg       0.85      0.87      0.86      1017\nweighted avg       0.87      0.86      0.86      1017\n\n('T:', '4.062988758087158')\n(0.3268741965293884,)\n('================================================',)\n('EPOCH ', '0.4180014985938405')\n              precision    recall  f1-score   support\n\n           0       0.90      0.86      0.88       413\n           1       0.80      0.85      0.82       261\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.574084520339966')\n('Epoch num - ', 1, ' and batch num ', 0)\n(0.35609856247901917,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.84      0.87       625\n           1       0.77      0.87      0.82       392\n\n   micro avg       0.85      0.85      0.85      1017\n   macro avg       0.84      0.86      0.85      1017\nweighted avg       0.86      0.85      0.85      1017\n\n('T:', '4.003525495529175')\n(0.3268200755119324,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.86      0.86       391\n           1       0.81      0.82      0.81       283\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.84      0.84      0.84       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.746225595474243')\n('Epoch num - ', 1, ' and batch num ', 1)\n(0.3795098662376404,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.88      0.89       411\n           1       0.82      0.87      0.84       263\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.88      0.87      0.87       674\n\n('T:', '6.809546232223511')\n('Epoch num - ', 1, ' and batch num ', 2)\n(0.30464860796928406,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.84      0.88       424\n           1       0.77      0.88      0.82       250\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.85       674\nweighted avg       0.87      0.86      0.86       674\n\n('T:', '6.810469388961792')\n('Epoch num - ', 1, ' and batch num ', 3)\n(0.34667065739631653,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.88      0.88       389\n           1       0.83      0.85      0.84       285\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.87      0.86      0.87       674\n\n('T:', '6.839190721511841')\n('Epoch num - ', 1, ' and batch num ', 4)\n(0.33492693305015564,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.87      0.89       395\n           1       0.83      0.86      0.85       279\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.87      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '8.633095502853394')\n('Epoch num - ', 1, ' and batch num ', 5)\n(0.32619762420654297,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.88      0.88       400\n           1       0.82      0.82      0.82       274\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '7.176547527313232')\n('Epoch num - ', 1, ' and batch num ', 6)\n(0.36710140109062195,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.87      0.90       417\n           1       0.81      0.88      0.84       257\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.87      0.87       674\nweighted avg       0.88      0.87      0.87       674\n\n('T:', '6.613764762878418')\n('Epoch num - ', 1, ' and batch num ', 7)\n(0.31114661693573,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.88      0.89       418\n           1       0.81      0.84      0.82       256\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.86       674\nweighted avg       0.87      0.86      0.86       674\n\n('T:', '6.766343116760254')\n('Epoch num - ', 1, ' and batch num ', 8)\n(0.31661826372146606,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.93      0.87      0.90       417\n           1       0.81      0.90      0.85       257\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.89      0.88       674\nweighted avg       0.89      0.88      0.88       674\n\n('T:', '6.700072526931763')\n('Epoch num - ', 1, ' and batch num ', 9)\n(0.28035199642181396,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.87      0.88       394\n           1       0.82      0.86      0.84       280\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.87      0.86      0.87       674\n\n('T:', '7.000113010406494')\n('Epoch num - ', 1, ' and batch num ', 10)\n(0.33776769042015076,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.85      0.87       625\n           1       0.78      0.85      0.81       392\n\n   micro avg       0.85      0.85      0.85      1017\n   macro avg       0.84      0.85      0.84      1017\nweighted avg       0.85      0.85      0.85      1017\n\n('T:', '4.134078025817871')\n(0.3211348354816437,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.86      0.88       414\n           1       0.80      0.85      0.82       260\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '7.012007474899292')\n('Epoch num - ', 1, ' and batch num ', 11)\n(0.36312589049339294,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.87      0.89       415\n           1       0.81      0.85      0.83       259\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.86       674\nweighted avg       0.87      0.86      0.86       674\n\n('T:', '6.911676406860352')\n('Epoch num - ', 1, ' and batch num ', 12)\n(0.32882609963417053,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.88      0.90       421\n           1       0.81      0.88      0.84       253\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.88      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '7.047507047653198')\n('Epoch num - ', 1, ' and batch num ', 13)\n(0.3146804869174957,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.87      0.86      0.86       393\n           1       0.81      0.81      0.81       281\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.84      0.84      0.84       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.84756875038147')\n('Epoch num - ', 1, ' and batch num ', 14)\n(0.3728407621383667,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.90      0.90       413\n           1       0.84      0.84      0.84       261\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.729957342147827')\n('Epoch num - ', 1, ' and batch num ', 15)\n(0.30565983057022095,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.88      0.89       394\n           1       0.83      0.86      0.85       280\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.87      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.82868218421936')\n('Epoch num - ', 1, ' and batch num ', 16)\n(0.3336139917373657,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.92      0.91       402\n           1       0.87      0.86      0.86       272\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.89      0.89      0.89       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '7.337883472442627')\n('Epoch num - ', 1, ' and batch num ', 17)\n(0.2851954698562622,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.91      0.89       368\n           1       0.89      0.84      0.86       306\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.88      0.87      0.88       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '7.083112955093384')\n('Epoch num - ', 1, ' and batch num ', 18)\n(0.35062599182128906,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.89      0.88       397\n           1       0.84      0.81      0.83       277\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.85      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.806186676025391')\n('Epoch num - ', 1, ' and batch num ', 19)\n(0.34560465812683105,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.89      0.89       410\n           1       0.83      0.84      0.84       264\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.87      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.5259833335876465')\n('Epoch num - ', 1, ' and batch num ', 20)\n(0.31790807843208313,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.87      0.89       625\n           1       0.80      0.86      0.83       392\n\n   micro avg       0.86      0.86      0.86      1017\n   macro avg       0.85      0.86      0.86      1017\nweighted avg       0.87      0.86      0.86      1017\n\n('T:', '4.019855499267578')\n(0.31404685974121094,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.88      0.88       418\n           1       0.80      0.82      0.81       256\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.8571624755859375')\n('Epoch num - ', 1, ' and batch num ', 21)\n(0.355747252702713,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.89      0.89       407\n           1       0.83      0.82      0.83       267\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.6534059047698975')\n('Epoch num - ', 1, ' and batch num ', 22)\n(0.35806599259376526,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.89      0.89       400\n           1       0.83      0.83      0.83       274\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '7.012956857681274')\n('Epoch num - ', 1, ' and batch num ', 23)\n(0.33995869755744934,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.87      0.87       399\n           1       0.82      0.81      0.82       275\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.84      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.613028526306152')\n('Epoch num - ', 1, ' and batch num ', 24)\n(0.3462870121002197,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.89      0.86       378\n           1       0.84      0.78      0.81       296\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.84      0.83      0.83       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.928330898284912')\n('Epoch num - ', 1, ' and batch num ', 25)\n(0.3762930929660797,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.86      0.87       411\n           1       0.79      0.80      0.79       263\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.83      0.83       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.923517942428589')\n('Epoch num - ', 1, ' and batch num ', 26)\n(0.3503812849521637,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.91      0.90       413\n           1       0.85      0.81      0.83       261\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.733457565307617')\n('Epoch num - ', 1, ' and batch num ', 27)\n(0.32115450501441956,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.89      0.89       405\n           1       0.83      0.82      0.83       269\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.911768913269043')\n('Epoch num - ', 1, ' and batch num ', 28)\n(0.3386599123477936,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.88      0.88       415\n           1       0.81      0.78      0.80       259\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.83      0.84       674\nweighted avg       0.84      0.85      0.85       674\n\n('T:', '6.4588282108306885')\n('Epoch num - ', 1, ' and batch num ', 29)\n(0.33395296335220337,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.89      0.87       411\n           1       0.81      0.76      0.79       263\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.83      0.83       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.646313905715942')\n('Epoch num - ', 1, ' and batch num ', 30)\n(0.36256498098373413,)\n('TEST COST',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.89      0.88      0.88       625\n           1       0.81      0.82      0.82       392\n\n   micro avg       0.86      0.86      0.86      1017\n   macro avg       0.85      0.85      0.85      1017\nweighted avg       0.86      0.86      0.86      1017\n\n('T:', '4.035719394683838')\n(0.32429927587509155,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.91      0.90       402\n           1       0.86      0.83      0.84       272\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.87      0.88      0.87       674\n\n('T:', '6.6548051834106445')\n('Epoch num - ', 1, ' and batch num ', 31)\n(0.3120284676551819,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.90      0.89       387\n           1       0.86      0.84      0.85       287\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '7.001136064529419')\n('Epoch num - ', 1, ' and batch num ', 32)\n(0.32370254397392273,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.91      0.91       413\n           1       0.85      0.85      0.85       261\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.88      0.88      0.88       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '7.009307146072388')\n('Epoch num - ', 1, ' and batch num ', 33)\n(0.31376418471336365,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.89      0.87       402\n           1       0.83      0.77      0.80       272\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.84      0.83      0.83       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '7.230253219604492')\n('Epoch num - ', 1, ' and batch num ', 34)\n(0.3722856938838959,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.90      0.88       391\n           1       0.85      0.81      0.83       283\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '7.0303795337677')\n('Epoch num - ', 1, ' and batch num ', 35)\n(0.33172833919525146,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.89      0.87       407\n           1       0.82      0.75      0.78       267\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.82      0.83       674\nweighted avg       0.83      0.84      0.83       674\n\n('T:', '6.884581565856934')\n('Epoch num - ', 1, ' and batch num ', 36)\n(0.3678165376186371,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.90      0.88       392\n           1       0.85      0.82      0.83       282\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '7.051877498626709')\n('Epoch num - ', 1, ' and batch num ', 37)\n(0.32002273201942444,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.90      0.89       415\n           1       0.84      0.81      0.82       259\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.868092060089111')\n('Epoch num - ', 1, ' and batch num ', 38)\n(0.30574095249176025,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.90      0.87       406\n           1       0.83      0.75      0.79       268\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.84      0.82      0.83       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.758570432662964')\n('Epoch num - ', 1, ' and batch num ', 39)\n(0.37744906544685364,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.91      0.90       411\n           1       0.86      0.83      0.84       263\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.88      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.935852289199829')\n('Epoch num - ', 1, ' and batch num ', 40)\n(0.31802132725715637,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.89      0.89       625\n           1       0.83      0.81      0.82       392\n\n   micro avg       0.86      0.86      0.86      1017\n   macro avg       0.86      0.85      0.86      1017\nweighted avg       0.86      0.86      0.86      1017\n\n('T:', '4.36426854133606')\n(0.3212052881717682,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.91      0.89       407\n           1       0.85      0.81      0.83       267\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.9056236743927')\n('Epoch num - ', 1, ' and batch num ', 41)\n(0.33450525999069214,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.90      0.88       406\n           1       0.84      0.80      0.82       268\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.6465935707092285')\n('Epoch num - ', 1, ' and batch num ', 42)\n(0.3363942801952362,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.93      0.90       399\n           1       0.89      0.81      0.85       275\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.88      0.87      0.88       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.578636407852173')\n('Epoch num - ', 1, ' and batch num ', 43)\n(0.3172990083694458,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.90      0.88       395\n           1       0.85      0.77      0.81       279\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.84      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.6784913539886475')\n('Epoch num - ', 1, ' and batch num ', 44)\n(0.3669562339782715,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.92      0.89       393\n           1       0.88      0.80      0.84       281\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.86      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.411459922790527')\n('Epoch num - ', 1, ' and batch num ', 45)\n(0.32693052291870117,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.92      0.89       404\n           1       0.86      0.77      0.81       270\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.84      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '7.029759168624878')\n('Epoch num - ', 1, ' and batch num ', 46)\n(0.36105865240097046,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.85      0.91      0.88       393\n           1       0.87      0.78      0.82       281\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.84      0.85       674\nweighted avg       0.86      0.86      0.85       674\n\n('T:', '6.9273903369903564')\n('Epoch num - ', 1, ' and batch num ', 47)\n(0.36839553713798523,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.90      0.88       416\n           1       0.83      0.77      0.80       258\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.84      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.6011528968811035')\n('Epoch num - ', 1, ' and batch num ', 48)\n(0.33999064564704895,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.92      0.88       408\n           1       0.86      0.75      0.80       266\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.83      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.765165328979492')\n('Epoch num - ', 1, ' and batch num ', 49)\n(0.3430209159851074,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.92      0.89       398\n           1       0.87      0.80      0.84       276\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.731033563613892')\n('Epoch num - ', 1, ' and batch num ', 50)\n(0.33075934648513794,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.89      0.88       625\n           1       0.82      0.78      0.80       392\n\n   micro avg       0.85      0.85      0.85      1017\n   macro avg       0.84      0.84      0.84      1017\nweighted avg       0.85      0.85      0.85      1017\n\n('T:', '4.07978892326355')\n(0.32851800322532654,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.90      0.89       413\n           1       0.83      0.80      0.82       261\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.963865518569946')\n('Epoch num - ', 1, ' and batch num ', 51)\n(0.32384780049324036,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.91      0.89       425\n           1       0.84      0.78      0.81       249\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.85      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.706271171569824')\n('Epoch num - ', 1, ' and batch num ', 52)\n(0.3195495307445526,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.89      0.89       429\n           1       0.80      0.81      0.80       245\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.695813179016113')\n('Epoch num - ', 1, ' and batch num ', 53)\n(0.3406272828578949,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.91      0.90       412\n           1       0.85      0.81      0.83       262\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.535452365875244')\n('Epoch num - ', 1, ' and batch num ', 54)\n(0.3249591290950775,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.90      0.91       449\n           1       0.81      0.84      0.83       225\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.767989635467529')\n('Epoch num - ', 1, ' and batch num ', 55)\n(0.29542890191078186,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.93      0.90       397\n           1       0.89      0.80      0.84       277\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.88      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.809057712554932')\n('Epoch num - ', 1, ' and batch num ', 56)\n(0.29871028661727905,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.90      0.90       418\n           1       0.84      0.84      0.84       256\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.776437282562256')\n('Epoch num - ', 1, ' and batch num ', 57)\n(0.31011763215065,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.91      0.89       413\n           1       0.85      0.79      0.82       261\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.85      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.909947633743286')\n('Epoch num - ', 1, ' and batch num ', 58)\n(0.3338221609592438,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.90      0.87       402\n           1       0.84      0.77      0.80       272\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.83      0.84       674\nweighted avg       0.85      0.85      0.84       674\n\n('T:', '6.844547748565674')\n('Epoch num - ', 1, ' and batch num ', 59)\n(0.36487045884132385,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.90      0.89       419\n           1       0.84      0.80      0.82       255\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.85      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.860576152801514')\n('Epoch num - ', 1, ' and batch num ', 60)\n(0.327582985162735,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.90      0.89       625\n           1       0.84      0.80      0.82       392\n\n   micro avg       0.86      0.86      0.86      1017\n   macro avg       0.86      0.85      0.85      1017\nweighted avg       0.86      0.86      0.86      1017\n\n('T:', '4.162123203277588')\n(0.3243049085140228,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.92      0.89       392\n           1       0.88      0.78      0.83       282\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.87      0.85      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.712737083435059')\n('Epoch num - ', 1, ' and batch num ', 61)\n(0.32493385672569275,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.92      0.89       398\n           1       0.88      0.79      0.83       276\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.9603590965271')\n('Epoch num - ', 1, ' and batch num ', 62)\n(0.34637537598609924,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.86      0.92      0.89       389\n           1       0.88      0.79      0.83       285\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.87      0.85      0.86       674\nweighted avg       0.87      0.86      0.86       674\n\n('T:', '7.075518846511841')\n('Epoch num - ', 1, ' and batch num ', 63)\n(0.34358590841293335,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.90      0.89       411\n           1       0.83      0.80      0.82       263\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '7.007785797119141')\n('Epoch num - ', 1, ' and batch num ', 64)\n(0.3375509977340698,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.93      0.90       391\n           1       0.90      0.80      0.84       283\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.88      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '7.068239450454712')\n('Epoch num - ', 1, ' and batch num ', 65)\n(0.31089872121810913,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.91      0.87       382\n           1       0.86      0.77      0.81       292\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.84      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.947488784790039')\n('Epoch num - ', 1, ' and batch num ', 66)\n(0.37732651829719543,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.90      0.90       429\n           1       0.82      0.81      0.82       245\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.667431354522705')\n('Epoch num - ', 1, ' and batch num ', 67)\n(0.30540701746940613,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.92      0.89       399\n           1       0.88      0.77      0.82       275\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.87      0.85      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.751076698303223')\n('Epoch num - ', 1, ' and batch num ', 68)\n(0.33222508430480957,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.91      0.89       408\n           1       0.85      0.80      0.83       266\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.938493251800537')\n('Epoch num - ', 1, ' and batch num ', 69)\n(0.3363305926322937,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.92      0.89       401\n           1       0.87      0.78      0.82       273\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.87      0.85      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.707987070083618')\n('Epoch num - ', 1, ' and batch num ', 70)\n(0.31318679451942444,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.89      0.88       625\n           1       0.82      0.79      0.81       392\n\n   micro avg       0.85      0.85      0.85      1017\n   macro avg       0.85      0.84      0.84      1017\nweighted avg       0.85      0.85      0.85      1017\n\n('T:', '4.0850958824157715')\n(0.3272227644920349,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.89      0.89       416\n           1       0.82      0.81      0.82       258\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.37880277633667')\n('Epoch num - ', 1, ' and batch num ', 71)\n(0.33047613501548767,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.93      0.90       407\n           1       0.88      0.81      0.84       267\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.88      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.737626314163208')\n('Epoch num - ', 1, ' and batch num ', 72)\n(0.322971910238266,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.91      0.88       397\n           1       0.86      0.78      0.82       277\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.85      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.690653085708618')\n('Epoch num - ', 1, ' and batch num ', 73)\n(0.33701977133750916,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.92      0.90       417\n           1       0.86      0.81      0.83       257\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.86      0.87       674\nweighted avg       0.87      0.88      0.87       674\n\n('T:', '6.83647894859314')\n('Epoch num - ', 1, ' and batch num ', 74)\n(0.30337369441986084,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.90      0.88       398\n           1       0.85      0.79      0.82       276\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.85      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.668645858764648')\n('Epoch num - ', 1, ' and batch num ', 75)\n(0.3166232407093048,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.92      0.88       376\n           1       0.89      0.78      0.83       298\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.85      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.900325298309326')\n('Epoch num - ', 1, ' and batch num ', 76)\n(0.34746411442756653,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.90      0.89       410\n           1       0.84      0.81      0.82       264\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.85      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.987691879272461')\n('Epoch num - ', 1, ' and batch num ', 77)\n(0.31925374269485474,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.89      0.87       423\n           1       0.80      0.76      0.78       251\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.82      0.83       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.570859670639038')\n('Epoch num - ', 1, ' and batch num ', 78)\n(0.362361341714859,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.95      0.90       389\n           1       0.91      0.78      0.84       285\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.88      0.86      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.878616809844971')\n('Epoch num - ', 1, ' and batch num ', 79)\n(0.31093940138816833,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.88      0.91      0.89       401\n           1       0.86      0.81      0.84       273\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.86      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.913106441497803')\n('Epoch num - ', 1, ' and batch num ', 80)\n(0.29941385984420776,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.89      0.89       625\n           1       0.83      0.82      0.83       392\n\n   micro avg       0.87      0.87      0.87      1017\n   macro avg       0.86      0.86      0.86      1017\nweighted avg       0.87      0.87      0.87      1017\n\n('T:', '4.085699796676636')\n(0.323589950799942,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.90      0.89       415\n           1       0.84      0.81      0.83       259\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.959327459335327')\n('Epoch num - ', 1, ' and batch num ', 81)\n(0.32633158564567566,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.91      0.89       388\n           1       0.87      0.81      0.84       286\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '7.051355361938477')\n('Epoch num - ', 1, ' and batch num ', 82)\n(0.3330991268157959,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.91      0.90       418\n           1       0.85      0.82      0.83       256\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.60317063331604')\n('Epoch num - ', 1, ' and batch num ', 83)\n(0.32078033685684204,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.91      0.89       409\n           1       0.85      0.80      0.82       265\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.85      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '7.136882066726685')\n('Epoch num - ', 1, ' and batch num ', 84)\n(0.3176999092102051,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.91      0.90       406\n           1       0.86      0.82      0.84       268\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.86      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.798837661743164')\n('Epoch num - ', 1, ' and batch num ', 85)\n(0.3100970387458801,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.88      0.88       416\n           1       0.80      0.80      0.80       258\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.84      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.748174428939819')\n('Epoch num - ', 1, ' and batch num ', 86)\n(0.34865766763687134,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.90      0.89       398\n           1       0.85      0.81      0.83       276\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.773221969604492')\n('Epoch num - ', 1, ' and batch num ', 87)\n(0.3340272307395935,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.91      0.89       395\n           1       0.87      0.79      0.83       279\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.85      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '7.355327367782593')\n('Epoch num - ', 1, ' and batch num ', 88)\n(0.324800580739975,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.89      0.89       423\n           1       0.81      0.81      0.81       251\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.619011402130127')\n('Epoch num - ', 1, ' and batch num ', 89)\n(0.3341352343559265,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.91      0.89       405\n           1       0.86      0.81      0.83       269\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.750806093215942')\n('Epoch num - ', 1, ' and batch num ', 90)\n(0.347697377204895,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.89      0.89       625\n           1       0.82      0.82      0.82       392\n\n   micro avg       0.86      0.86      0.86      1017\n   macro avg       0.85      0.85      0.85      1017\nweighted avg       0.86      0.86      0.86      1017\n\n('T:', '4.095563888549805')\n(0.32342368364334106,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.90      0.90       410\n           1       0.85      0.84      0.84       264\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.679466962814331')\n('Epoch num - ', 1, ' and batch num ', 91)\n(0.30805328488349915,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.91      0.89       393\n           1       0.86      0.80      0.83       281\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.85      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.977048635482788')\n('Epoch num - ', 1, ' and batch num ', 92)\n(0.32324638962745667,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.89      0.88       410\n           1       0.82      0.78      0.80       264\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.84      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.924065351486206')\n('Epoch num - ', 1, ' and batch num ', 93)\n(0.33151477575302124,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.90      0.90       413\n           1       0.84      0.85      0.85       261\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.88      0.88       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.97067403793335')\n('Epoch num - ', 1, ' and batch num ', 94)\n(0.30417996644973755,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.89      0.88       412\n           1       0.82      0.81      0.81       262\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.98192834854126')\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "('Epoch num - ', 1, ' and batch num ', 95)\n(0.33251529932022095,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.88      0.89       407\n           1       0.82      0.84      0.83       267\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.859920978546143')\n('Epoch num - ', 1, ' and batch num ', 96)\n(0.33365166187286377,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.90      0.89       405\n           1       0.85      0.81      0.83       269\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.916929006576538')\n('Epoch num - ', 1, ' and batch num ', 97)\n(0.317070335149765,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.89      0.90       433\n           1       0.81      0.83      0.82       241\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '7.046077251434326')\n('Epoch num - ', 1, ' and batch num ', 98)\n(0.34528231620788574,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.90      0.87       400\n           1       0.84      0.78      0.81       274\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.84      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.6513566970825195')\n('Epoch num - ', 1, ' and batch num ', 99)\n(0.3491435647010803,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.89      0.89       406\n           1       0.83      0.82      0.83       268\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.5892579555511475')\n('Epoch num - ', 1, ' and batch num ', 100)\n(0.3591553270816803,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.88      0.89       625\n           1       0.82      0.84      0.83       392\n\n   micro avg       0.87      0.87      0.87      1017\n   macro avg       0.86      0.86      0.86      1017\nweighted avg       0.87      0.87      0.87      1017\n\n('T:', '4.077682256698608')\n(0.32386937737464905,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.89      0.89       418\n           1       0.81      0.82      0.82       256\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.847764730453491')\n('Epoch num - ', 1, ' and batch num ', 101)\n(0.3353865146636963,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.91      0.90       421\n           1       0.84      0.82      0.83       253\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.86      0.87       674\nweighted avg       0.87      0.88      0.88       674\n\n('T:', '6.7913713455200195')\n('Epoch num - ', 1, ' and batch num ', 102)\n(0.3090839385986328,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.87      0.86       403\n           1       0.81      0.78      0.79       271\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.83      0.83       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.641786813735962')\n('Epoch num - ', 1, ' and batch num ', 103)\n(0.36203035712242126,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.90      0.90       414\n           1       0.84      0.83      0.83       260\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.855018377304077')\n('Epoch num - ', 1, ' and batch num ', 104)\n(0.3318096995353699,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.88      0.88       400\n           1       0.83      0.81      0.82       274\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.909525632858276')\n('Epoch num - ', 1, ' and batch num ', 105)\n(0.34044647216796875,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.88      0.90       429\n           1       0.81      0.86      0.83       245\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.87      0.87       674\nweighted avg       0.88      0.87      0.87       674\n\n('T:', '6.727878093719482')\n('Epoch num - ', 1, ' and batch num ', 106)\n(0.31443557143211365,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.90      0.90       413\n           1       0.84      0.84      0.84       261\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.7917938232421875')\n('Epoch num - ', 1, ' and batch num ', 107)\n(0.3167564570903778,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.89      0.89       393\n           1       0.85      0.83      0.84       281\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.950150489807129')\n('Epoch num - ', 1, ' and batch num ', 108)\n(0.31319960951805115,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.88      0.88       404\n           1       0.82      0.81      0.82       270\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.939321756362915')\n('Epoch num - ', 1, ' and batch num ', 109)\n(0.3507249355316162,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.90      0.88       387\n           1       0.86      0.81      0.83       287\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.378275156021118')\n('Epoch num - ', 1, ' and batch num ', 110)\n(0.3360121548175812,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.88      0.89       625\n           1       0.81      0.84      0.83       392\n\n   micro avg       0.86      0.86      0.86      1017\n   macro avg       0.85      0.86      0.86      1017\nweighted avg       0.86      0.86      0.86      1017\n\n('T:', '4.023990631103516')\n(0.3317335844039917,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.87      0.86       386\n           1       0.82      0.80      0.81       288\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.84      0.84      0.84       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.8652966022491455')\n('Epoch num - ', 1, ' and batch num ', 111)\n(0.3752245008945465,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.90      0.87      0.88       425\n           1       0.79      0.83      0.81       249\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.85      0.85       674\nweighted avg       0.86      0.85      0.86       674\n\n('T:', '6.586538076400757')\n('Epoch num - ', 1, ' and batch num ', 112)\n(0.34815502166748047,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.89      0.89       398\n           1       0.84      0.84      0.84       276\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.930258274078369')\n('Epoch num - ', 1, ' and batch num ', 113)\n(0.29683297872543335,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.86      0.88       407\n           1       0.80      0.86      0.83       267\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.68608546257019')\n('Epoch num - ', 1, ' and batch num ', 114)\n(0.32828640937805176,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.90      0.90       409\n           1       0.85      0.84      0.84       265\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.734084129333496')\n('Epoch num - ', 1, ' and batch num ', 115)\n(0.29318416118621826,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.92      0.90       393\n           1       0.88      0.83      0.85       281\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.88      0.87      0.88       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.947221517562866')\n('Epoch num - ', 1, ' and batch num ', 116)\n(0.3147643506526947,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.90      0.90       413\n           1       0.84      0.85      0.84       261\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.818191051483154')\n('Epoch num - ', 1, ' and batch num ', 117)\n(0.3141665756702423,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.89      0.90       410\n           1       0.83      0.86      0.84       264\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.958038091659546')\n('Epoch num - ', 1, ' and batch num ', 118)\n(0.32018157839775085,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.87      0.88       408\n           1       0.81      0.84      0.82       266\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.619560718536377')\n('Epoch num - ', 1, ' and batch num ', 119)\n(0.3452167212963104,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.90      0.89       396\n           1       0.86      0.82      0.84       278\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.560521364212036')\n('Epoch num - ', 1, ' and batch num ', 120)\n(0.31689414381980896,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.86      0.88       625\n           1       0.80      0.86      0.83       392\n\n   micro avg       0.86      0.86      0.86      1017\n   macro avg       0.85      0.86      0.86      1017\nweighted avg       0.86      0.86      0.86      1017\n\n('T:', '4.068486928939819')\n(0.3372502326965332,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.90      0.91       410\n           1       0.85      0.88      0.86       264\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.88      0.89      0.89       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.7054853439331055')\n('Epoch num - ', 1, ' and batch num ', 121)\n(0.29062333703041077,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.91      0.91       398\n           1       0.87      0.85      0.86       276\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.89      0.88      0.88       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.772683143615723')\n('Epoch num - ', 1, ' and batch num ', 122)\n(0.29855436086654663,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.88      0.89       424\n           1       0.80      0.82      0.81       250\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.866666555404663')\n('Epoch num - ', 1, ' and batch num ', 123)\n(0.3451126515865326,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.90      0.89       397\n           1       0.85      0.84      0.85       277\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.6522722244262695')\n('Epoch num - ', 1, ' and batch num ', 124)\n(0.30502426624298096,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.90      0.89       404\n           1       0.85      0.83      0.84       270\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.86      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.91991662979126')\n('Epoch num - ', 1, ' and batch num ', 125)\n(0.2981645166873932,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.90      0.90       392\n           1       0.86      0.85      0.85       282\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.88      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.790628433227539')\n('Epoch num - ', 1, ' and batch num ', 126)\n(0.2962596118450165,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.88      0.90       413\n           1       0.82      0.87      0.85       261\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.88      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.923880338668823')\n('Epoch num - ', 1, ' and batch num ', 127)\n(0.318430095911026,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.87      0.86       391\n           1       0.82      0.78      0.80       283\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.83      0.83       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.726771831512451')\n('Epoch num - ', 1, ' and batch num ', 128)\n(0.38743433356285095,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.91      0.88      0.89       422\n           1       0.81      0.86      0.83       252\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.87      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.685495853424072')\n('Epoch num - ', 1, ' and batch num ', 129)\n(0.299883097410202,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.91      0.91       390\n           1       0.87      0.88      0.88       284\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.89      0.89      0.89       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.608790397644043')\n('Epoch num - ', 1, ' and batch num ', 130)\n(0.30578863620758057,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.85      0.88       625\n           1       0.78      0.85      0.82       392\n\n   micro avg       0.85      0.85      0.85      1017\n   macro avg       0.84      0.85      0.85      1017\nweighted avg       0.86      0.85      0.85      1017\n\n('T:', '4.0588414669036865')\n(0.33819785714149475,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.88      0.88       408\n           1       0.81      0.83      0.82       266\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.818702220916748')\n('Epoch num - ', 1, ' and batch num ', 131)\n(0.33301249146461487,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.86      0.88       411\n           1       0.80      0.87      0.83       263\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.86       674\nweighted avg       0.87      0.86      0.86       674\n\n('T:', '7.1210784912109375')\n('Epoch num - ', 1, ' and batch num ', 132)\n(0.3278217017650604,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.86      0.87       382\n           1       0.83      0.86      0.84       292\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.8934783935546875')\n('Epoch num - ', 1, ' and batch num ', 133)\n(0.3517903983592987,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.86      0.87       414\n           1       0.79      0.82      0.80       260\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.84      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.76769757270813')\n('Epoch num - ', 1, ' and batch num ', 134)\n(0.36797961592674255,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.85      0.88       414\n           1       0.79      0.87      0.83       260\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '7.109633207321167')\n('Epoch num - ', 1, ' and batch num ', 135)\n(0.34601259231567383,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.90      0.91       392\n           1       0.86      0.88      0.87       282\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.89      0.89      0.89       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.771573543548584')\n('Epoch num - ', 1, ' and batch num ', 136)\n(0.27027323842048645,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.93      0.87      0.90       422\n           1       0.81      0.90      0.85       252\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.88      0.88       674\nweighted avg       0.89      0.88      0.88       674\n\n('T:', '6.704998731613159')\n('Epoch num - ', 1, ' and batch num ', 137)\n(0.2928830683231354,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.93      0.87      0.90       444\n           1       0.78      0.88      0.83       230\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.87      0.86       674\nweighted avg       0.88      0.87      0.88       674\n\n('T:', '6.7920002937316895')\n('Epoch num - ', 1, ' and batch num ', 138)\n(0.33864128589630127,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.93      0.87      0.90       422\n           1       0.81      0.89      0.85       252\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.88      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.698089361190796')\n('Epoch num - ', 1, ' and batch num ', 139)\n(0.29653698205947876,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.86      0.88       419\n           1       0.79      0.85      0.82       255\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '7.029149532318115')\n('Epoch num - ', 1, ' and batch num ', 140)\n(0.3811969757080078,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.87      0.89       625\n           1       0.81      0.88      0.84       392\n\n   micro avg       0.87      0.87      0.87      1017\n   macro avg       0.87      0.88      0.87      1017\nweighted avg       0.88      0.87      0.88      1017\n\n('T:', '4.106878757476807')\n(0.3221791982650757,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.86      0.89       434\n           1       0.78      0.86      0.82       240\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.85       674\nweighted avg       0.87      0.86      0.86       674\n\n('T:', '6.504969358444214')\n('Epoch num - ', 1, ' and batch num ', 141)\n(0.33070558309555054,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.89      0.90       410\n           1       0.83      0.86      0.84       264\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.950589656829834')\n('Epoch num - ', 1, ' and batch num ', 142)\n(0.3329920470714569,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.87      0.89       391\n           1       0.83      0.87      0.85       283\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '7.033011198043823')\n('Epoch num - ', 1, ' and batch num ', 143)\n(0.33130723237991333,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.87      0.90       419\n           1       0.80      0.88      0.84       255\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.88      0.87       674\nweighted avg       0.88      0.87      0.87       674\n\n('T:', '6.712569236755371')\n('Epoch num - ', 1, ' and batch num ', 144)\n(0.3203422427177429,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.93      0.89      0.91       403\n           1       0.84      0.90      0.87       271\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.89      0.89      0.89       674\nweighted avg       0.90      0.89      0.89       674\n\n('T:', '6.768495321273804')\n('Epoch num - ', 1, ' and batch num ', 145)\n(0.25465500354766846,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.88      0.89       398\n           1       0.83      0.87      0.85       276\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.848817348480225')\n('Epoch num - ', 1, ' and batch num ', 146)\n(0.3173140585422516,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.93      0.87      0.90       419\n           1       0.80      0.89      0.84       255\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.88      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.682737588882446')\n('Epoch num - ', 1, ' and batch num ', 147)\n(0.3369741141796112,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.86      0.89       408\n           1       0.80      0.87      0.84       266\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.87      0.86       674\nweighted avg       0.87      0.86      0.87       674\n\n('T:', '6.830218553543091')\n('Epoch num - ', 1, ' and batch num ', 148)\n(0.34820324182510376,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.88      0.88       387\n           1       0.84      0.84      0.84       287\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.900213956832886')\n('Epoch num - ', 1, ' and batch num ', 149)\n(0.32709047198295593,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.93      0.88      0.91       407\n           1       0.83      0.91      0.87       267\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.88      0.89      0.89       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.590330123901367')\n('Epoch num - ', 1, ' and batch num ', 150)\n(0.30234384536743164,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.85      0.88       625\n           1       0.78      0.87      0.82       392\n\n   micro avg       0.85      0.85      0.85      1017\n   macro avg       0.85      0.86      0.85      1017\nweighted avg       0.86      0.85      0.86      1017\n\n('T:', '4.040389776229858')\n(0.3324342370033264,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.85      0.88       419\n           1       0.78      0.87      0.82       255\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.86      0.85       674\nweighted avg       0.86      0.85      0.86       674\n\n('T:', '6.670804977416992')\n('Epoch num - ', 1, ' and batch num ', 151)\n(0.34746813774108887,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.85      0.89       429\n           1       0.77      0.88      0.82       245\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.87      0.85       674\nweighted avg       0.87      0.86      0.86       674\n\n('T:', '6.791431903839111')\n('Epoch num - ', 1, ' and batch num ', 152)\n(0.3169519305229187,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.87      0.89       411\n           1       0.81      0.85      0.83       263\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.87      0.86      0.86       674\n\n('T:', '6.901392936706543')\n('Epoch num - ', 1, ' and batch num ', 153)\n(0.34014734625816345,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.85      0.88       406\n           1       0.80      0.88      0.84       268\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.87      0.86       674\nweighted avg       0.87      0.86      0.87       674\n\n('T:', '6.690953254699707')\n('Epoch num - ', 1, ' and batch num ', 154)\n(0.34044378995895386,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.95      0.88      0.91       408\n           1       0.84      0.92      0.88       266\n\n   micro avg       0.90      0.90      0.90       674\n   macro avg       0.89      0.90      0.90       674\nweighted avg       0.90      0.90      0.90       674\n\n('T:', '6.935499668121338')\n('Epoch num - ', 1, ' and batch num ', 155)\n(0.2786160111427307,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.90      0.91       397\n           1       0.86      0.89      0.87       277\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.89      0.89      0.89       674\nweighted avg       0.90      0.89      0.89       674\n\n('T:', '7.253480434417725')\n('Epoch num - ', 1, ' and batch num ', 156)\n(0.2754402458667755,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.88      0.90       392\n           1       0.84      0.89      0.86       282\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.88      0.88      0.88       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.96144962310791')\n('Epoch num - ', 1, ' and batch num ', 157)\n(0.30718886852264404,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.86      0.88       399\n           1       0.81      0.85      0.83       275\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.783126354217529')\n('Epoch num - ', 1, ' and batch num ', 158)\n(0.30954012274742126,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.93      0.88      0.90       410\n           1       0.82      0.89      0.85       264\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.88      0.88       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '7.230456829071045')\n('Epoch num - ', 1, ' and batch num ', 159)\n(0.3098212778568268,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.86      0.89       413\n           1       0.80      0.89      0.84       261\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.87      0.87       674\nweighted avg       0.88      0.87      0.87       674\n\n('T:', '6.84579062461853')\n('Epoch num - ', 1, ' and batch num ', 160)\n(0.3182923495769501,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.86      0.89       625\n           1       0.80      0.88      0.84       392\n\n   micro avg       0.87      0.87      0.87      1017\n   macro avg       0.86      0.87      0.86      1017\nweighted avg       0.87      0.87      0.87      1017\n\n('T:', '4.0879881381988525')\n(0.32440683245658875,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.91      0.87      0.89       418\n           1       0.80      0.86      0.83       256\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.86       674\nweighted avg       0.87      0.86      0.87       674\n\n('T:', '6.441942930221558')\n('Epoch num - ', 1, ' and batch num ', 161)\n(0.3398624360561371,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.87      0.88       386\n           1       0.83      0.87      0.85       288\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.998349666595459')\n('Epoch num - ', 1, ' and batch num ', 162)\n(0.3371695280075073,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.87      0.89       410\n           1       0.82      0.88      0.85       264\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.88      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.711792469024658')\n('Epoch num - ', 1, ' and batch num ', 163)\n(0.342208594083786,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.87      0.89       397\n           1       0.82      0.87      0.84       277\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.87      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.7602574825286865')\n('Epoch num - ', 1, ' and batch num ', 164)\n(0.3166695237159729,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.88      0.89       401\n           1       0.83      0.86      0.85       273\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.88      0.87      0.87       674\n\n('T:', '6.892381906509399')\n('Epoch num - ', 1, ' and batch num ', 165)\n(0.31334182620048523,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.87      0.89       410\n           1       0.81      0.88      0.84       264\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.87      0.87       674\nweighted avg       0.88      0.87      0.87       674\n\n('T:', '6.756215810775757')\n('Epoch num - ', 1, ' and batch num ', 166)\n(0.31624194979667664,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.93      0.88      0.90       405\n           1       0.83      0.90      0.86       269\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.88      0.89      0.88       674\nweighted avg       0.89      0.88      0.88       674\n\n('T:', '6.894455194473267')\n('Epoch num - ', 1, ' and batch num ', 167)\n(0.27025142312049866,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.94      0.85      0.89       433\n           1       0.77      0.90      0.83       241\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.87      0.86       674\nweighted avg       0.88      0.86      0.87       674\n\n('T:', '6.7604498863220215')\n('Epoch num - ', 1, ' and batch num ', 168)\n(0.3613566756248474,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.93      0.87      0.90       402\n           1       0.82      0.90      0.86       272\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.88      0.88      0.88       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.606152772903442')\n('Epoch num - ', 1, ' and batch num ', 169)\n(0.2872222065925598,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.94      0.86      0.90       414\n           1       0.80      0.91      0.85       260\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.88      0.87       674\nweighted avg       0.89      0.88      0.88       674\n\n('T:', '6.645728588104248')\n('Epoch num - ', 1, ' and batch num ', 170)\n(0.30601468682289124,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.85      0.89       625\n           1       0.79      0.89      0.83       392\n\n   micro avg       0.86      0.86      0.86      1017\n   macro avg       0.86      0.87      0.86      1017\nweighted avg       0.87      0.86      0.87      1017\n\n('T:', '4.036086559295654')\n(0.32106128334999084,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.93      0.89      0.91       401\n           1       0.85      0.89      0.87       273\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.89      0.89      0.89       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.5605950355529785')\n('Epoch num - ', 1, ' and batch num ', 171)\n(0.2849772274494171,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.87      0.89       401\n           1       0.82      0.87      0.85       273\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.612223148345947')\n('Epoch num - ', 1, ' and batch num ', 172)\n(0.31366774439811707,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.88      0.89       411\n           1       0.82      0.87      0.84       263\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.88      0.87      0.87       674\n\n('T:', '6.829488515853882')\n('Epoch num - ', 1, ' and batch num ', 173)\n(0.30628764629364014,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.88      0.88       371\n           1       0.85      0.86      0.85       303\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.572895765304565')\n('Epoch num - ', 1, ' and batch num ', 174)\n(0.3319634199142456,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.85      0.88       408\n           1       0.79      0.87      0.83       266\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.8593480587005615')\n('Epoch num - ', 1, ' and batch num ', 175)\n(0.3498750627040863,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.86      0.89       409\n           1       0.80      0.89      0.84       265\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.87      0.87       674\nweighted avg       0.88      0.87      0.87       674\n\n('T:', '6.816581726074219')\n('Epoch num - ', 1, ' and batch num ', 176)\n(0.3280026912689209,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.88      0.90       404\n           1       0.83      0.88      0.85       270\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.88      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.886907577514648')\n('Epoch num - ', 1, ' and batch num ', 177)\n(0.3109564781188965,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.91      0.90      0.90       404\n           1       0.85      0.87      0.86       270\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.88      0.88      0.88       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.944304943084717')\n('Epoch num - ', 1, ' and batch num ', 178)\n(0.2917918264865875,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.88      0.89       388\n           1       0.84      0.87      0.86       286\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.961806058883667')\n('Epoch num - ', 1, ' and batch num ', 179)\n(0.30209997296333313,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.87      0.89       419\n           1       0.80      0.87      0.84       255\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.87      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.5308568477630615')\n('Epoch num - ', 1, ' and batch num ', 180)\n(0.3363828957080841,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.93      0.86      0.89       625\n           1       0.80      0.90      0.84       392\n\n   micro avg       0.87      0.87      0.87      1017\n   macro avg       0.86      0.88      0.87      1017\nweighted avg       0.88      0.87      0.87      1017\n\n('T:', '4.041273593902588')\n(0.30398696660995483,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.87      0.89       413\n           1       0.80      0.87      0.84       261\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.87      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.727557182312012')\n('Epoch num - ', 1, ' and batch num ', 181)\n(0.29576754570007324,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.89      0.89       391\n           1       0.85      0.84      0.85       283\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '7.025609254837036')\n('Epoch num - ', 1, ' and batch num ', 182)\n(0.31009146571159363,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.89      0.89       382\n           1       0.86      0.87      0.86       292\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.88      0.88      0.88       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '7.454396486282349')\n('Epoch num - ', 1, ' and batch num ', 183)\n(0.31904518604278564,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.85      0.88       405\n           1       0.80      0.88      0.84       269\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.87      0.86       674\nweighted avg       0.87      0.86      0.87       674\n\n('T:', '6.769139051437378')\n('Epoch num - ', 1, ' and batch num ', 184)\n(0.33727362751960754,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.85      0.88       402\n           1       0.80      0.88      0.84       272\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.750363826751709')\n('Epoch num - ', 1, ' and batch num ', 185)\n(0.3531414270401001,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.94      0.87      0.90       411\n           1       0.82      0.91      0.86       263\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.88      0.89      0.88       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.603602647781372')\n('Epoch num - ', 1, ' and batch num ', 186)\n(0.2889833450317383,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.93      0.87      0.90       431\n           1       0.79      0.88      0.83       243\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.87      0.86       674\nweighted avg       0.88      0.87      0.87       674\n\n('T:', '6.673778057098389')\n('Epoch num - ', 1, ' and batch num ', 187)\n(0.3189784288406372,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.93      0.86      0.90       419\n           1       0.80      0.90      0.85       255\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.88      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.861532926559448')\n('Epoch num - ', 1, ' and batch num ', 188)\n(0.3092653155326843,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.87      0.88       402\n           1       0.81      0.86      0.84       272\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.87      0.86      0.87       674\n\n('T:', '6.872612476348877')\n('Epoch num - ', 1, ' and batch num ', 189)\n(0.3307259976863861,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.90      0.88       378\n           1       0.86      0.83      0.84       296\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.866179466247559')\n('Epoch num - ', 1, ' and batch num ', 190)\n(0.36642101407051086,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.86      0.89       625\n           1       0.80      0.88      0.84       392\n\n   micro avg       0.87      0.87      0.87      1017\n   macro avg       0.86      0.87      0.86      1017\nweighted avg       0.87      0.87      0.87      1017\n\n('T:', '4.0086753368377686')\n(0.30464768409729004,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.85      0.88       402\n           1       0.80      0.88      0.84       272\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.698185920715332')\n('Epoch num - ', 1, ' and batch num ', 191)\n(0.34279462695121765,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.85      0.88       415\n           1       0.78      0.85      0.82       259\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.84      0.85      0.85       674\nweighted avg       0.86      0.85      0.85       674\n\n('T:', '6.811878681182861')\n('Epoch num - ', 1, ' and batch num ', 192)\n(0.35645756125450134,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.87      0.89       411\n           1       0.81      0.87      0.84       263\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.87      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.518577575683594')\n('Epoch num - ', 1, ' and batch num ', 193)\n(0.31686273217201233,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.93      0.87      0.90       422\n           1       0.80      0.89      0.84       252\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.86      0.88      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.567333698272705')\n('Epoch num - ', 1, ' and batch num ', 194)\n(0.306037575006485,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.93      0.86      0.89       426\n           1       0.79      0.89      0.83       248\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.87      0.86       674\nweighted avg       0.88      0.87      0.87       674\n\n('T:', '6.867645740509033')\n('Epoch num - ', 1, ' and batch num ', 195)\n(0.316712349653244,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.93      0.88      0.91       416\n           1       0.83      0.90      0.86       258\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.88      0.89      0.89       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.663580656051636')\n('Epoch num - ', 1, ' and batch num ', 196)\n(0.26669344305992126,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.86      0.89       421\n           1       0.79      0.87      0.83       253\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.86       674\nweighted avg       0.87      0.86      0.86       674\n\n('T:', '7.037627696990967')\n('Epoch num - ', 1, ' and batch num ', 197)\n(0.3134559988975525,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.93      0.90      0.91       397\n           1       0.86      0.90      0.88       277\n\n   micro avg       0.90      0.90      0.90       674\n   macro avg       0.89      0.90      0.90       674\nweighted avg       0.90      0.90      0.90       674\n\n('T:', '6.621389389038086')\n('Epoch num - ', 1, ' and batch num ', 198)\n(0.2730776071548462,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.89      0.90       398\n           1       0.84      0.87      0.86       276\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.88      0.88       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.5019683837890625')\n('Epoch num - ', 1, ' and batch num ', 199)\n(0.30335432291030884,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.88      0.89       398\n           1       0.83      0.86      0.84       276\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.740136384963989')\n('Epoch num - ', 1, ' and batch num ', 200)\n(0.3102918565273285,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.87      0.89       625\n           1       0.80      0.87      0.84       392\n\n   micro avg       0.87      0.87      0.87      1017\n   macro avg       0.86      0.87      0.86      1017\nweighted avg       0.87      0.87      0.87      1017\n\n('T:', '4.0721755027771')\n(0.30404117703437805,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.93      0.89      0.91       423\n           1       0.83      0.89      0.86       251\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.88      0.89      0.88       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.7042059898376465')\n('Epoch num - ', 1, ' and batch num ', 201)\n(0.28909769654273987,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.84      0.87       409\n           1       0.78      0.85      0.81       265\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.83      0.84      0.84       674\nweighted avg       0.85      0.84      0.84       674\n\n('T:', '6.765485763549805')\n('Epoch num - ', 1, ' and batch num ', 202)\n(0.3654884696006775,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.90      0.89       390\n           1       0.86      0.83      0.85       284\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.90038275718689')\n('Epoch num - ', 1, ' and batch num ', 203)\n(0.3272055685520172,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.87      0.88       414\n           1       0.80      0.85      0.82       260\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.86      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.505367994308472')\n('Epoch num - ', 1, ' and batch num ', 204)\n(0.333424836397171,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.91      0.91       403\n           1       0.86      0.89      0.87       271\n\n   micro avg       0.90      0.90      0.90       674\n   macro avg       0.89      0.90      0.89       674\nweighted avg       0.90      0.90      0.90       674\n\n('T:', '6.935806512832642')\n('Epoch num - ', 1, ' and batch num ', 205)\n(0.2757401168346405,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.87      0.89       407\n           1       0.82      0.88      0.85       267\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.88      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.749183893203735')\n('Epoch num - ', 1, ' and batch num ', 206)\n(0.3141579329967499,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.88      0.89       413\n           1       0.82      0.84      0.83       261\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.982534170150757')\n('Epoch num - ', 1, ' and batch num ', 207)\n(0.31299692392349243,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.92      0.92       393\n           1       0.89      0.88      0.88       281\n\n   micro avg       0.90      0.90      0.90       674\n   macro avg       0.90      0.90      0.90       674\nweighted avg       0.90      0.90      0.90       674\n\n('T:', '6.836652755737305')\n('Epoch num - ', 1, ' and batch num ', 208)\n(0.2637859880924225,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.88      0.89       396\n           1       0.84      0.87      0.85       278\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.88      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.716408014297485')\n('Epoch num - ', 1, ' and batch num ', 209)\n(0.27899205684661865,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.87      0.88       409\n           1       0.80      0.84      0.82       265\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.86      0.85      0.86       674\n\n('T:', '6.74319314956665')\n('Epoch num - ', 1, ' and batch num ', 210)\n(0.36995911598205566,)\n('TEST COST',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.91      0.88      0.90       625\n           1       0.82      0.87      0.84       392\n\n   micro avg       0.88      0.88      0.88      1017\n   macro avg       0.87      0.87      0.87      1017\nweighted avg       0.88      0.88      0.88      1017\n\n('T:', '4.062181234359741')\n(0.2911030948162079,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.89      0.90       404\n           1       0.84      0.86      0.85       270\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.818427324295044')\n('Epoch num - ', 1, ' and batch num ', 211)\n(0.3167267143726349,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.86      0.88       399\n           1       0.81      0.87      0.84       275\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.87      0.86      0.86       674\n\n('T:', '6.924945831298828')\n('Epoch num - ', 1, ' and batch num ', 212)\n(0.3284851014614105,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.89      0.89       400\n           1       0.84      0.82      0.83       274\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.58191180229187')\n('Epoch num - ', 1, ' and batch num ', 213)\n(0.308056503534317,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.89      0.88       395\n           1       0.84      0.82      0.83       279\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.85      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.8752899169921875')\n('Epoch num - ', 1, ' and batch num ', 214)\n(0.342898964881897,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.88      0.89       412\n           1       0.82      0.85      0.84       262\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.87      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.514625787734985')\n('Epoch num - ', 1, ' and batch num ', 215)\n(0.31608298420906067,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.91      0.91       398\n           1       0.87      0.86      0.86       276\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.89      0.89      0.89       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.529114723205566')\n('Epoch num - ', 1, ' and batch num ', 216)\n(0.28983819484710693,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.90      0.91       413\n           1       0.85      0.88      0.86       261\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.88      0.89      0.89       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.82315468788147')\n('Epoch num - ', 1, ' and batch num ', 217)\n(0.31120195984840393,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.92      0.91       397\n           1       0.88      0.85      0.86       277\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.89      0.88      0.88       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.899011135101318')\n('Epoch num - ', 1, ' and batch num ', 218)\n(0.2950892150402069,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.89      0.90       414\n           1       0.83      0.86      0.85       260\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.88      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.746642589569092')\n('Epoch num - ', 1, ' and batch num ', 219)\n(0.32475781440734863,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.89      0.90       412\n           1       0.83      0.85      0.84       262\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.829315185546875')\n('Epoch num - ', 1, ' and batch num ', 220)\n(0.3094225525856018,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.88      0.89       625\n           1       0.82      0.85      0.83       392\n\n   micro avg       0.87      0.87      0.87      1017\n   macro avg       0.86      0.86      0.86      1017\nweighted avg       0.87      0.87      0.87      1017\n\n('T:', '4.009708642959595')\n(0.29646405577659607,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.90      0.89       403\n           1       0.84      0.81      0.82       271\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.85      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.865839242935181')\n('Epoch num - ', 1, ' and batch num ', 221)\n(0.3468535840511322,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.89      0.90       412\n           1       0.83      0.85      0.84       262\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.7200927734375')\n('Epoch num - ', 1, ' and batch num ', 222)\n(0.3106520473957062,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.90      0.89       406\n           1       0.84      0.81      0.83       268\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.85      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.7258360385894775')\n('Epoch num - ', 1, ' and batch num ', 223)\n(0.3228055238723755,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.90      0.90       411\n           1       0.84      0.84      0.84       263\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.845558404922485')\n('Epoch num - ', 1, ' and batch num ', 224)\n(0.2806110978126526,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.90      0.88       389\n           1       0.86      0.81      0.83       285\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.932091236114502')\n('Epoch num - ', 1, ' and batch num ', 225)\n(0.3297659754753113,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.89      0.88       396\n           1       0.84      0.81      0.82       278\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.832306385040283')\n('Epoch num - ', 1, ' and batch num ', 226)\n(0.356977641582489,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.88      0.91      0.90       389\n           1       0.88      0.84      0.85       285\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.88      0.87      0.88       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.841558218002319')\n('Epoch num - ', 1, ' and batch num ', 227)\n(0.3100900948047638,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.89      0.88       400\n           1       0.83      0.80      0.82       274\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '6.661730527877808')\n('Epoch num - ', 1, ' and batch num ', 228)\n(0.35128656029701233,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.89      0.89       417\n           1       0.83      0.83      0.83       257\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.833490371704102')\n('Epoch num - ', 1, ' and batch num ', 229)\n(0.30317655205726624,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.89      0.89       408\n           1       0.83      0.82      0.82       266\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.85      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.799631118774414')\n('Epoch num - ', 1, ' and batch num ', 230)\n(0.3395827114582062,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.89      0.90       625\n           1       0.84      0.85      0.84       392\n\n   micro avg       0.88      0.88      0.88      1017\n   macro avg       0.87      0.87      0.87      1017\nweighted avg       0.88      0.88      0.88      1017\n\n('T:', '4.245724439620972')\n(0.2949773073196411,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.89      0.88       400\n           1       0.84      0.81      0.82       274\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.85      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.803235769271851')\n('Epoch num - ', 1, ' and batch num ', 231)\n(0.3230227828025818,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.89      0.89       408\n           1       0.84      0.84      0.84       266\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.83590841293335')\n('Epoch num - ', 1, ' and batch num ', 232)\n(0.3348381519317627,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.90      0.90       413\n           1       0.84      0.83      0.83       261\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.927920579910278')\n('Epoch num - ', 1, ' and batch num ', 233)\n(0.31014424562454224,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.91      0.91       424\n           1       0.85      0.86      0.86       250\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.89      0.89      0.89       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.746565580368042')\n('Epoch num - ', 1, ' and batch num ', 234)\n(0.2836652100086212,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.90      0.89       385\n           1       0.87      0.83      0.85       289\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.723831415176392')\n('Epoch num - ', 1, ' and batch num ', 235)\n(0.3320583403110504,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.93      0.91       395\n           1       0.90      0.84      0.87       279\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.89      0.88      0.89       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.893678188323975')\n('Epoch num - ', 1, ' and batch num ', 236)\n(0.2821440100669861,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.92      0.89       394\n           1       0.88      0.78      0.82       280\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.85      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.763371229171753')\n('Epoch num - ', 1, ' and batch num ', 237)\n(0.3199818432331085,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.91      0.92       431\n           1       0.85      0.86      0.85       243\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.88      0.89      0.88       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.689729928970337')\n('Epoch num - ', 1, ' and batch num ', 238)\n(0.2615763545036316,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.92      0.90       394\n           1       0.88      0.84      0.86       280\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.88      0.88      0.88       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.8330535888671875')\n('Epoch num - ', 1, ' and batch num ', 239)\n(0.29266735911369324,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.91      0.90       406\n           1       0.86      0.83      0.84       268\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.695570468902588')\n('Epoch num - ', 1, ' and batch num ', 240)\n(0.310673326253891,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.89      0.89       625\n           1       0.83      0.84      0.83       392\n\n   micro avg       0.87      0.87      0.87      1017\n   macro avg       0.86      0.86      0.86      1017\nweighted avg       0.87      0.87      0.87      1017\n\n('T:', '4.040590047836304')\n(0.299879789352417,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.93      0.91       400\n           1       0.89      0.83      0.86       274\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.89      0.88      0.88       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.607014179229736')\n('Epoch num - ', 1, ' and batch num ', 241)\n(0.31429991126060486,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.90      0.90       418\n           1       0.84      0.84      0.84       256\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.978921890258789')\n('Epoch num - ', 1, ' and batch num ', 242)\n(0.3198820650577545,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.89      0.91      0.90       410\n           1       0.86      0.83      0.84       264\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.932783365249634')\n('Epoch num - ', 1, ' and batch num ', 243)\n(0.32039862871170044,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.91      0.89       410\n           1       0.85      0.80      0.83       264\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.89107084274292')\n('Epoch num - ', 1, ' and batch num ', 244)\n(0.31217160820961,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.92      0.88       377\n           1       0.88      0.79      0.83       297\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.85      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.9256861209869385')\n('Epoch num - ', 1, ' and batch num ', 245)\n(0.3621855080127716,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.90      0.89       413\n           1       0.83      0.82      0.82       261\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.7192747592926025')\n('Epoch num - ', 1, ' and batch num ', 246)\n(0.3394441306591034,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.90      0.89       409\n           1       0.85      0.82      0.83       265\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.485933542251587')\n('Epoch num - ', 1, ' and batch num ', 247)\n(0.3117022216320038,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.82      0.93      0.87       380\n           1       0.89      0.73      0.80       294\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.85      0.83      0.84       674\nweighted avg       0.85      0.84      0.84       674\n\n('T:', '7.040683269500732')\n('Epoch num - ', 1, ' and batch num ', 248)\n(0.3636634647846222,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.89      0.91       440\n           1       0.81      0.85      0.83       234\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.86      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.750305652618408')\n('Epoch num - ', 1, ' and batch num ', 249)\n(0.2808492183685303,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.90      0.91       423\n           1       0.84      0.85      0.84       251\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.88      0.88       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.646068096160889')\n('Epoch num - ', 1, ' and batch num ', 250)\n(0.27543511986732483,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.90      0.90       625\n           1       0.84      0.83      0.84       392\n\n   micro avg       0.88      0.88      0.88      1017\n   macro avg       0.87      0.87      0.87      1017\nweighted avg       0.88      0.88      0.88      1017\n\n('T:', '4.068134546279907')\n(0.29435601830482483,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.90      0.90       424\n           1       0.83      0.83      0.83       250\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.807307481765747')\n('Epoch num - ', 1, ' and batch num ', 251)\n(0.29340922832489014,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.91      0.88       399\n           1       0.85      0.77      0.81       275\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.84      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '7.325176954269409')\n('Epoch num - ', 1, ' and batch num ', 252)\n(0.3606976568698883,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.92      0.89       402\n           1       0.87      0.79      0.82       272\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.87      0.85      0.86       674\nweighted avg       0.87      0.86      0.86       674\n\n('T:', '6.527091979980469')\n('Epoch num - ', 1, ' and batch num ', 253)\n(0.3301117718219757,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.92      0.89       392\n           1       0.87      0.80      0.84       282\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '7.126119613647461')\n('Epoch num - ', 1, ' and batch num ', 254)\n(0.3109314441680908,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.91      0.90       409\n           1       0.85      0.82      0.83       265\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.86      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '7.0101587772369385')\n('Epoch num - ', 1, ' and batch num ', 255)\n(0.33028197288513184,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.91      0.91       419\n           1       0.85      0.86      0.86       255\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.88      0.88      0.88       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.850324392318726')\n('Epoch num - ', 1, ' and batch num ', 256)\n(0.28187406063079834,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.93      0.91       408\n           1       0.89      0.81      0.85       266\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.88      0.87      0.88       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.556765556335449')\n('Epoch num - ', 1, ' and batch num ', 257)\n(0.319843053817749,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.93      0.90       396\n           1       0.88      0.80      0.84       278\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.88      0.86      0.87       674\nweighted avg       0.88      0.88      0.87       674\n\n('T:', '7.276018857955933')\n('Epoch num - ', 1, ' and batch num ', 258)\n(0.3250442147254944,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.91      0.89       406\n           1       0.85      0.79      0.82       268\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.85      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.628488063812256')\n('Epoch num - ', 1, ' and batch num ', 259)\n(0.32649922370910645,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.88      0.92      0.90       410\n           1       0.87      0.80      0.83       264\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.86      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.818358659744263')\n('Epoch num - ', 1, ' and batch num ', 260)\n(0.3325806260108948,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.90      0.89       625\n           1       0.84      0.81      0.83       392\n\n   micro avg       0.87      0.87      0.87      1017\n   macro avg       0.86      0.86      0.86      1017\nweighted avg       0.87      0.87      0.87      1017\n\n('T:', '4.078894853591919')\n(0.30061522126197815,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.95      0.92       395\n           1       0.92      0.83      0.87       279\n\n   micro avg       0.90      0.90      0.90       674\n   macro avg       0.90      0.89      0.90       674\nweighted avg       0.90      0.90      0.90       674\n\n('T:', '7.2073140144348145')\n('Epoch num - ', 1, ' and batch num ', 261)\n(0.2862146198749542,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.94      0.91       405\n           1       0.90      0.82      0.86       269\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.89      0.88      0.89       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.895205020904541')\n('Epoch num - ', 1, ' and batch num ', 262)\n(0.27913326025009155,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.90      0.86       392\n           1       0.84      0.76      0.79       282\n\n   micro avg       0.84      0.84      0.84       674\n   macro avg       0.84      0.83      0.83       674\nweighted avg       0.84      0.84      0.84       674\n\n('T:', '6.539383888244629')\n('Epoch num - ', 1, ' and batch num ', 263)\n(0.38312336802482605,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.85      0.92      0.88       397\n           1       0.87      0.77      0.81       277\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.84      0.85       674\nweighted avg       0.86      0.86      0.85       674\n\n('T:', '6.796098709106445')\n('Epoch num - ', 1, ' and batch num ', 264)\n(0.33387643098831177,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.93      0.92       431\n           1       0.87      0.84      0.86       243\n\n   micro avg       0.90      0.90      0.90       674\n   macro avg       0.89      0.89      0.89       674\nweighted avg       0.90      0.90      0.90       674\n\n('T:', '6.583298921585083')\n('Epoch num - ', 1, ' and batch num ', 265)\n(0.2650029957294464,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.93      0.90       391\n           1       0.90      0.81      0.85       283\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.88      0.87      0.88       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.828634977340698')\n('Epoch num - ', 1, ' and batch num ', 266)\n(0.3123225271701813,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.93      0.91      0.92       432\n           1       0.85      0.87      0.86       242\n\n   micro avg       0.90      0.90      0.90       674\n   macro avg       0.89      0.89      0.89       674\nweighted avg       0.90      0.90      0.90       674\n\n('T:', '6.983674764633179')\n('Epoch num - ', 1, ' and batch num ', 267)\n(0.2640790641307831,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.93      0.90       385\n           1       0.90      0.81      0.85       289\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.88      0.87      0.88       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '7.0780723094940186')\n('Epoch num - ', 1, ' and batch num ', 268)\n(0.32470259070396423,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.92      0.89       386\n           1       0.88      0.82      0.85       288\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.88      0.87      0.87       674\nweighted avg       0.88      0.88      0.87       674\n\n('T:', '6.75287127494812')\n('Epoch num - ', 1, ' and batch num ', 269)\n(0.3316442668437958,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.90      0.89       406\n           1       0.84      0.81      0.83       268\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.85      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.804378986358643')\n('Epoch num - ', 1, ' and batch num ', 270)\n(0.3424105644226074,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.91      0.90       625\n           1       0.85      0.83      0.84       392\n\n   micro avg       0.88      0.88      0.88      1017\n   macro avg       0.87      0.87      0.87      1017\nweighted avg       0.88      0.88      0.88      1017\n\n('T:', '4.08537483215332')\n(0.2985592186450958,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.91      0.90       409\n           1       0.86      0.82      0.84       265\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.88      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.735077857971191')\n('Epoch num - ', 1, ' and batch num ', 271)\n(0.3234759271144867,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.86      0.92      0.89       404\n           1       0.86      0.78      0.82       270\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.85      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.76088547706604')\n('Epoch num - ', 1, ' and batch num ', 272)\n(0.35121187567710876,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.91      0.89       401\n           1       0.86      0.81      0.83       273\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.668095827102661')\n('Epoch num - ', 1, ' and batch num ', 273)\n(0.34058722853660583,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.95      0.92       402\n           1       0.92      0.84      0.88       272\n\n   micro avg       0.91      0.91      0.91       674\n   macro avg       0.91      0.90      0.90       674\nweighted avg       0.91      0.91      0.91       674\n\n('T:', '6.724207401275635')\n('Epoch num - ', 1, ' and batch num ', 274)\n(0.2757624387741089,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.89      0.89       427\n           1       0.82      0.81      0.81       247\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.85      0.85      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.704539060592651')\n('Epoch num - ', 1, ' and batch num ', 275)\n(0.3243088722229004,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.90      0.92      0.91       410\n           1       0.87      0.84      0.85       264\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.88      0.88      0.88       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.820111513137817')\n('Epoch num - ', 1, ' and batch num ', 276)\n(0.30492103099823,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.91      0.91       412\n           1       0.86      0.86      0.86       262\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.89      0.89      0.89       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.7051331996917725')\n('Epoch num - ', 1, ' and batch num ', 277)\n(0.2914365231990814,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.96      0.92       398\n           1       0.93      0.80      0.86       276\n\n   micro avg       0.90      0.90      0.90       674\n   macro avg       0.90      0.88      0.89       674\nweighted avg       0.90      0.90      0.89       674\n\n('T:', '7.275891542434692')\n('Epoch num - ', 1, ' and batch num ', 278)\n(0.29630470275878906,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.90      0.88       417\n           1       0.82      0.78      0.80       257\n\n   micro avg       0.85      0.85      0.85       674\n   macro avg       0.85      0.84      0.84       674\nweighted avg       0.85      0.85      0.85       674\n\n('T:', '7.050547122955322')\n('Epoch num - ', 1, ' and batch num ', 279)\n(0.3636074662208557,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.92      0.92      0.92       423\n           1       0.87      0.87      0.87       251\n\n   micro avg       0.90      0.90      0.90       674\n   macro avg       0.90      0.90      0.90       674\nweighted avg       0.90      0.90      0.90       674\n\n('T:', '6.838160514831543')\n('Epoch num - ', 1, ' and batch num ', 280)\n(0.27062052488327026,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.91      0.90       625\n           1       0.85      0.82      0.83       392\n\n   micro avg       0.87      0.87      0.87      1017\n   macro avg       0.87      0.86      0.87      1017\nweighted avg       0.87      0.87      0.87      1017\n\n('T:', '4.043457746505737')\n(0.30030155181884766,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.91      0.90       409\n           1       0.86      0.84      0.85       265\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.88      0.87      0.88       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.854750394821167')\n('Epoch num - ', 1, ' and batch num ', 281)\n(0.3053838610649109,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.92      0.91       402\n           1       0.87      0.84      0.86       272\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.88      0.88      0.88       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.665930986404419')\n('Epoch num - ', 1, ' and batch num ', 282)\n(0.2986431121826172,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.93      0.90       401\n           1       0.88      0.79      0.83       273\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.86      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.74487566947937')\n('Epoch num - ', 1, ' and batch num ', 283)\n(0.320448637008667,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.91      0.90       418\n           1       0.85      0.83      0.84       256\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.691253185272217')\n('Epoch num - ', 1, ' and batch num ', 284)\n(0.31742581725120544,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.91      0.90       409\n           1       0.85      0.84      0.85       265\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.919244289398193')\n('Epoch num - ', 1, ' and batch num ', 285)\n(0.30062419176101685,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.91      0.91       415\n           1       0.86      0.85      0.85       259\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.88      0.88      0.88       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.8297717571258545')\n('Epoch num - ', 1, ' and batch num ', 286)\n(0.2841763496398926,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.90      0.88       400\n           1       0.84      0.80      0.82       274\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.85      0.85       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.878967523574829')\n('Epoch num - ', 1, ' and batch num ', 287)\n(0.32671624422073364,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.88      0.91      0.90       402\n           1       0.86      0.82      0.84       272\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.86      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.925223112106323')\n('Epoch num - ', 1, ' and batch num ', 288)\n(0.3315771222114563,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.91      0.90       406\n           1       0.86      0.84      0.85       268\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.88      0.87      0.88       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.87039041519165')\n('Epoch num - ', 1, ' and batch num ', 289)\n(0.305925577878952,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.89      0.92      0.90       402\n           1       0.88      0.83      0.85       272\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.88      0.88      0.88       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '7.302136659622192')\n('Epoch num - ', 1, ' and batch num ', 290)\n(0.31495073437690735,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.90      0.90       625\n           1       0.84      0.84      0.84       392\n\n   micro avg       0.88      0.88      0.88      1017\n   macro avg       0.87      0.87      0.87      1017\nweighted avg       0.88      0.88      0.88      1017\n\n('T:', '4.073349952697754')\n(0.2995900809764862,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.90      0.90      0.90       422\n           1       0.83      0.84      0.84       252\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.87      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.875120401382446')\n('Epoch num - ', 1, ' and batch num ', 291)\n(0.30633530020713806,)\n('================================================',)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.90      0.91      0.91       405\n           1       0.87      0.85      0.86       269\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.88      0.88      0.88       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.7887914180755615')\n('Epoch num - ', 1, ' and batch num ', 292)\n(0.29287460446357727,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.89      0.90       410\n           1       0.83      0.87      0.85       264\n\n   micro avg       0.88      0.88      0.88       674\n   macro avg       0.87      0.88      0.87       674\nweighted avg       0.88      0.88      0.88       674\n\n('T:', '6.8743860721588135')\n('Epoch num - ', 1, ' and batch num ', 293)\n(0.31362712383270264,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.91      0.89       382\n           1       0.88      0.82      0.85       292\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.86      0.87       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '7.132935285568237')\n('Epoch num - ', 1, ' and batch num ', 294)\n(0.3135625720024109,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.89      0.90       426\n           1       0.82      0.84      0.83       248\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.86      0.87      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '6.905402421951294')\n('Epoch num - ', 1, ' and batch num ', 295)\n(0.2933495342731476,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.92      0.91       414\n           1       0.87      0.85      0.86       260\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.89      0.88      0.89       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.69625997543335')\n('Epoch num - ', 1, ' and batch num ', 296)\n(0.2886629104614258,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.92      0.89       393\n           1       0.87      0.80      0.84       281\n\n   micro avg       0.87      0.87      0.87       674\n   macro avg       0.87      0.86      0.86       674\nweighted avg       0.87      0.87      0.87       674\n\n('T:', '7.089927434921265')\n('Epoch num - ', 1, ' and batch num ', 297)\n(0.32752928137779236,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.87      0.90      0.89       398\n           1       0.85      0.80      0.83       276\n\n   micro avg       0.86      0.86      0.86       674\n   macro avg       0.86      0.85      0.86       674\nweighted avg       0.86      0.86      0.86       674\n\n('T:', '6.905339479446411')\n('Epoch num - ', 1, ' and batch num ', 298)\n(0.33972954750061035,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.93      0.89      0.91       415\n           1       0.84      0.89      0.86       259\n\n   micro avg       0.89      0.89      0.89       674\n   macro avg       0.88      0.89      0.89       674\nweighted avg       0.89      0.89      0.89       674\n\n('T:', '6.894330739974976')\n('Epoch num - ', 1, ' and batch num ', 299)\n(0.29005739092826843,)\n('================================================',)\n              precision    recall  f1-score   support\n\n           0       0.84      0.94      0.89        68\n           1       0.92      0.79      0.85        56\n\n   micro avg       0.87      0.87      0.87       124\n   macro avg       0.88      0.86      0.87       124\nweighted avg       0.88      0.87      0.87       124\n\n('T:', '1.453035593032837')\n('Epoch num - ', 1, ' and batch num ', 300)\n(0.31159913539886475,)\n('TEST COST',)\n              precision    recall  f1-score   support\n\n           0       0.91      0.89      0.90       625\n           1       0.83      0.86      0.84       392\n\n   micro avg       0.88      0.88      0.88      1017\n   macro avg       0.87      0.87      0.87      1017\nweighted avg       0.88      0.88      0.88      1017\n\n('T:', '4.091364145278931')\n(0.29300615191459656,)\n('================================================',)\n('EPOCH ', '0.322676045950069')\ncompleted\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "35d58a539b058d3534840f726e914052dc434d5e"
      },
      "cell_type": "code",
      "source": "# test = pd.read_csv(\"../input/quora-insincere-questions-classification/test.csv\",index_col = None)\ntest = pd.read_csv(\"../input/test.csv\",index_col = None)\nlog(\"Test Shape\",test.shape)\ntest[\"question_text\"] = [preprocess(each) for each in test[\"question_text\"]]\nlog(\"preprocessing words complete\")\n\ntest[\"x\"]  = test[\"question_text\"]\n\ntotal_result = []\ntx_batches = get_batches(x = test[\"x\"],chunks = batches)\ntx_batches = [each for each in tx_batches if each.shape[0] != 0]\nfor i,e in enumerate(tx_batches):\n    xv = [get_vectors(each,glv,pad = None) for each in e]\n    pred =  model.forward(xv)\n    result =pred[:,0].detach().numpy()\n    [total_result.append(r) for r in result]\n    print(i)\ntest[\"result\"] = total_result\ntest[\"prediction\"] = [ 1 if each >= threshold else 0 for each in test.result]\ntest[[\"qid\",\"prediction\"]].to_csv(\"submission.csv\",index = None)\nprint(\"submitted\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b0037fd5a035cece310a1a44c83aae1ce90f1953"
      },
      "cell_type": "code",
      "source": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)\n",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}